====== 1 ========

SCIENTIFIC AMERICAN

Digital Issue + Subscription ?

Read or download this issue’s articles online. Plus, subscribe to get Online and Tablet access to the next 12 new issues to be released as well as Online access to up to the past 4 years of archives. *A printed copy of this issue is not included.

$39.99

====== 2 ========

NEWSLETTER SIGN-UP



====== 3 ========

THE FOREIGNERS AT YOUR THANKSGIVING TABLE

The foreigners are here. They’re in our supermarkets. They’re in our schools. They may even be in the room with you right now (cue dramatic music). I’m not talking about the hardworking migrant workers who toil long hours to collect the food we eat (and who deserve our support, kindness and respect). The foreigners in this case are the food we eat.

But most of these foods were first developed in what President Trump once referred to as “shithole countries.” Wheat was originally domesticated by the inhabitants of Syria, Turkey and Iraq roughly 11,000 years ago. Around the same time in China, early farmers developed rice and, later, soybeans. Corn was bred in central Mexico approximately 9,000 years ago and was so important to the Olmec, Maya and other Mesoamerican civilizations that they even had maize gods. All of these foreigners are around us in some capacity, and they form the backbone of our great economy.

And foreigners aren’t just in our food; they’re also in our most cherished pieces of children’s literature and film. The popular children’s book Charlotte’s Web and the 1995 film Babe are not gripping tales designed to teach life lessons so much as they are tales of foreigners trying to escape persecution and death in rural America. The entire barnyard is a collection of nefarious characters. Babe and Wilbur’s ancestors were wild boars in the Middle East and China that were domesticated into our friendly, if not slightly troublesome, pigs. All of the chickens, roosters and ducks are originally from the jungles of southern China, Laos, Thailand and Vietnam. Cows first roamed the mountains of the Middle East, India and Pakistan, while horses all come from the steppes of eastern Russia and Mongolia.

In Trump’s America, the beloved sheep would undoubtedly be flagged at the airport for extra screening because their ancestors lived in the lawless mountains of Turkey, Iraq and Iran. Even Duchess the Cat, the one animal in Babe who doesn’t seem destined for the chopping block, is not above suspicion because of her ancient Egyptian heritage.

I often envision people, once they realize the origins of their food, repeatedly reliving that scene from Ghostbusters where Sigourney Weaver opens her fridge to discover the demon Zuul living in her fridge. The painting American Gothic by Grant Wood, depicting a stern-looking farming couple is seared into our collective consciousness as what it means to be an American, and what traditional American values are. I imagine that if you pan out from that image, you’ll see the real truth behind America. You’ll see hard-working farmers planting Mexican corn, milking Middle Eastern cows and harvesting Chinese soybeans. Trump and his Republican allies will try and build all the walls they want and scare as many people as will listen. But for this Thanksgiving, the “foreigners” are already here, and they’ve been here for a long time.

====== 4 ========

6 STRANGE FACTS ABOUT THE INTERSTELLAR VISITOR 'OUMUAMUA

On October 19, 2017, the first interstellar object, ‘Oumuamua, was discovered by the Pan-STARRS survey. The experience was similar to having a surprise guest for dinner show up from another country. By examining this guest, we can learn about the culture of that country without the need to travel there—a good thing in this case, given that it would take us a hundred thousand years to visit even the nearest star using conventional chemical rockets.

Surprisingly, our first interstellar guest appeared to be weird and unlike anything we have seen before. By the time we realized it, the guest was already out the door with its image fading into the dark street, so we did not have a chance to get a second look at its mysterious qualities. Below is a list of six peculiarities exhibited by ‘Oumuamua:

Assuming that other planetary systems resemble the solar system, Pan-STARRS should not have discovered this or any other interstellar rock in the first place. In a paper published a decade ago, we predicted an abundance of interstellar asteroids that is smaller by many (two to eight) orders of magnitude than needed to explain the discovery of ‘Oumuamua, assuming it’s a member of a random population of objects. Put another way, ‘Oumuamua implies that the population of interstellar objects is far greater than expected. Each star in the Milky Way needs to eject 1015 such objects during its lifetime to account for a population as large as ‘Oumuamua implies. Thus, the nurseries of ‘Oumuamua-like objects must be different from what we know based on our own solar system. ‘Oumuamua originated from a very special frame of reference, the so-called local standard of rest (LSR), which is defined by averaging the random motions of all the stars in the vicinity of the sun. Only one star in 500 is moving as slowly as ‘Oumuamua in that frame. The LSR is the ideal frame for camouflage, namely for hiding the origins of an object and avoiding its association with any particular star. The relative motion between ‘Oumuamua and the sun reflects the motion of the sun relative to the LSR. ‘Oumuamua is like a buoy sitting at rest on the surface of the ocean, with the solar system running into it like a fast ship. Could there be an array of buoys that serves as a network of relay stations or road posts, defining the average galactic frame of reference in interstellar space? Most interstellar asteroids are expected to be ripped away from their parent star when they lie in the outskirts of their birth planetary system (such as our solar system’s Oort cloud, which extends to 100,000 times the Earth-sun separation), where they are most loosely bound to the star’s gravity. At these outskirts, they can be removed with a small velocity nudge of less than a kilometer per second, in which case they will maintain the speed of their host star relative to the LSR. If ‘Oumuamua came from a typical star, it must have been ejected with an unusually large velocity kick. To make things more unusual, its kick should have been equal and opposite to the velocity of its parent star relative to the LSR, which is about 20 kilometers per second for a typical star like the sun. The dynamical origin of ‘Oumuamua is extremely rare no matter how you look at it. This is surprising, since the first foreign guest to a dinner party should be statistically common (especially given the larger than usual population inferred in the first point above). We do not have a photo of ‘Oumuamua, but its brightness owing to reflected sunlight varied by a factor of 10 as it rotated periodically every eight hours. This implies that ‘Oumuamua has an extreme elongated shape with its length at least five to 10 times larger than its projected width. Moreover, an analysis of its tumbling motion concluded that it would be at the highest excitation state expected from its tumultuous journey, if it has a pancake-like geometry. The inferred shape is more extreme than for all asteroids previously seen in the solar system, which have an length-to-width ratio of at most three. The Spitzer Space Telescope did not detect any heat in the form of infrared radiation from ‘Oumuamua. Given the surface temperature dictated by ‘Oumuamua’s trajectory near the sun, this sets an upper limit on its size of hundreds of meters. Based on this size limit, ‘Oumuamua must be unusually shiny, with a reflectance that is at least 10 times higher than exhibited by solar system asteroids. The trajectory of ‘Oumuamua deviated from that expected based on the sun’s gravity alone. The deviation is small (a tenth of a percent) but highly statistically significant. Comets exhibit such a behavior when ices on their surface heat up from solar illumination and evaporate, generating thrust through the rocket effect. The extra push for ‘Oumuamua could have originated by cometary outgassing if at least a tenth of its mass evaporated. But such massive evaporation would have naturally led to the appearance of a cometary tail, and none was seen. The Spitzer telescope observations also place tight limits on any carbon-based molecules or dust around ‘Oumuamua and rule out the possibility that normal cometary outgassing is at play (unless it is composed of pure water). Moreover, cometary outgassing would have changed the rotation period of ‘Oumuamua, and no such change was observed. Altogether, ‘Oumuamua does not appear to be a typical comet nor a typical asteroid, even as it represents a population that is far more abundant than expected.

The extra push exhibited by ‘Oumuamua’s orbit could not have originated from a breakup into pieces because such an event would have provided a single, impulsive kick, unlike the continuous push that was observed. If cometary outgassing is ruled out and the inferred excess force is real, only one possibility remains: an extra push due to radiation pressure from the sun. In order for this push to be effective, ‘Oumuamua needs to be less than a millimeter thick but with a size of at least 20 meters (for a perfect reflector), resembling a lightsail of artificial origin. In this case ‘Oumuamua would resemble the solar sail demonstrated by the Japanese mission IKAROS or the lightsail contemplated for the Starshot initiative. An artificial origin offers the startling possibility that we discovered “a message in a bottle” following years of failed searches for radio signals from alien civilizations. Reassuringly, such a lightsail would survive collisions with interstellar atoms and dust as it travels throughout the galaxy.

In contemplating the possibility of an artificial origin, we should keep in mind what Sherlock Holmes said: “when you have excluded the impossible, whatever remains, however improbable, must be the truth.” The Kepler satellite revealed that about a quarter of all the stars in the Milky Way have a habitable planet of the size of the Earth, with the potential to have liquid water on its surface and the chemistry of life as we know it. It is therefore conceivable that interstellar space is full of artificially made debris, either in the form of devices that serve a purpose on a reconnaissance mission or in the form of defunct equipment. However, to validate an exotic artificial origin for ‘Oumuamua, we need more data. As Carl Sagan said, “extraordinary claims require extraordinary evidence.”

In fact, the possibility of a targeted mission adds some explanatory power. It is unlikely that 1015 solar sails are launched per star to make up a random population of ‘Oumuamua-like objects. This would require the unreasonable rate of a launch every five minutes from a planetary system even if all civilizations live as long as the full lifetime of the Milky Way galaxy. Instead, the required numbers could be reduced dramatically if ‘Oumuamua-like objects do not sample all possible orbits randomly but rather follow special orbits that dive into the innermost, habitable regions of planetary systems like our solar system.

‘Oumuamua moves too fast for our chemical rockets to catch up with it now without a gravitational assist from planets. But since it would take ‘Oumuamua thousands of years to leave the solar system entirely, getting a closer look of it through a flyby remains a possibility if we were to develop new technologies for faster space travel within a decade or two. Interestingly, some interstellar objects that pass close to Jupiter can lose energy and get captured by the solar system. These are dinner guests who bumped into a wall on their way out and stayed around after dinner. The Sun-Jupiter system acts as a fishing net. If we can identify trapped interstellar objects through their unusual bound orbits with unusually high inclinations relative to the solar system plane, we could design missions to visit them and learn more about their nature.

Alternatively, we can wait for the next interstellar guest to show up. Within a few years, the Large Synoptic Survey Telescope (LSST) will become operational and be far more sensitive to the detection of ‘Oumuamua-like objects. It should therefore discover many such objects within its first year of operation. If it does not find any, we will know that ‘Oumuamua was special and that we must chase this guest down the street in order to figure out its origin.

Studying interstellar objects resembles my favorite activity when walking along the beach with my daughters. We enjoy picking up seashells that were swept ashore and learning about their different origins. Every now and then, we find a plastic bottle that indicates an artificial origin. Similarly, astronomers should examine any object that enters the solar system and study its properties. There is no doubt that the six peculiar features of ‘Oumuamua have the potential to usher in a dramatic new era in space science.

====== 5 ========

THE GREAT BARRIER REEF IS “IN FOR A ROUGH RIDE”

During summer 2017 a large swath of Australia’s Great Barrier Reef—normally a riot of electric oranges, reds and other colors—turned ghostly pale.

Unusually warm water temperatures, partly due to global warming, had caused the corals to expel from their tissues the symbiotic algae that provide them with food and give them their brilliant hues. It was the second mass-bleaching event to hit the reef in as many years. Together, the back-to-back events hit two thirds of the reef.

Now, with the 2019 Australian summer poised to begin, atmospheric scientists are predicting an El Niño—a recurring period marked by warmer temperatures in the tropical Pacific Ocean. This potential for high temperatures again poses a threat to the Great Barrier Reef, one that marine biologist Terry Hughes—a high-profile champion of coral reef protection—will be watching, looking for signs of more damage to the reef as he continues to push for protecting it.

Hughes thinks there are some worthy mitigation efforts to explore, such as reforesting the watersheds that drain into the reef to prevent pollution-bearing runoff. But ultimately he believes the key to saving corals lies in addressing greenhouse gas emissions that fuel global warming.

Professor Terry Hughes. Credit: Arccoe Wikimedia

Hughes’s efforts to raise awareness about the fate of the 2,300-kilometer-long coral reef—the largest on the planet and home to thousands of marine species—have put him at odds with business and political interests. Last month it emerged the Australian Research Council (ARC) would drop its funding of the coral reef institute Hughes directs at James Cook University in Queensland—a move decried by ocean scientists around the world. (The ARC and the current conservative Australian government have said the decision was not politically motivated, according to news reports.) Last week Hughes was awarded The John Maddox Prize for championing scientific evidence in the face of hostility. Scientific American caught up with him at the annual Falling Walls science conference in Berlin earlier this month and spoke about the future of the Great Barrier Reef.

[An edited transcript of the interview follows.]

What is your outlook for the Great Barrier Reef in the coming months?

NOAA [the U.S. National Oceanic and Atmospheric Administration] and the Australian Bureau of Meteorology are both projecting a high likelihood of an El Niño event forming later this year. If that happens, the likelihood of bleaching when summer sea temperatures peak next March would be very high, but we won’t know for sure until about January. A well-timed cyclone could cool the water despite the long-term forecast. But you have to be careful what you wish for. In 2016 the southern third of the Great Barrier Reef was rescued by a spent cyclone that brought the [water] temperature down about 2 to 3 degrees Celsius. But with Cyclone Debbie in 2017, the bleaching had already occurred and the storm was a category 4 when it hit the coast—so it was actually very damaging and destructive [to the reef].

How do you monitor a bleaching event?

Our aerial surveys, which we match to satellite temperature data, are reef-wide. It takes us seven or eight days to crisscross the entire Great Barrier Reef in a small plane flying up to eight hours a day. It’s pretty grueling but that’s the best way that we have of getting the full picture. We ground-truth all of that [data] underwater [during dives]. Each event that we study has a different geography. The 2016 event was very much a northern affair. The maps for the 2017 bleaching will show that the hottest part of the reef—the part that had the most bleaching—was in the center.

Is there any area of the reef you are especially worried about?

My worst nightmare is that the bottom [southern] third of the Great Barrier Reef, which escaped the last two events, will bleach. It was simply good luck that prevented it from bleaching in 2016 and 2017. Those reefs have very high numbers of branching corals that happen to be the most susceptible to bleaching. So if it does get a blast of heat next summer or some summer soon, there will be high levels of mortality. That would mean all sectors of the reef will have been hit within a handful of years.

How did the Australian government respond to the bleaching events?

The Great Barrier Reef story in Australia, following the unprecedented back-to-back bleaching, is very politically contentious. You would think an appropriate response by the government would be to declare, for instance, that it wasn’t going to proceed with the world’s largest coal mine [with a coal shipping terminal near the reef] or that it would ramp up its renewable energy targets. Neither has occurred. The government has put quite a lot of money into investigating different interventions. Some are downright silly—the [underwater cooling] fans, the floating sunscreen. There’s a campaign to ban plastic straws. If you were cynical, you would say that it was more about giving the appearance of helping reefs when the elephant in the room is still climate change. There’s also money for improving water quality. Runoff of sediment and nutrients from agriculture into the inner part of the Great Barrier Reef is an important issue, but the amount of funding that’s being spent on that is nowhere near sufficient to reach the government’s own targets. As the country responsible for the Great Barrier Reef World Heritage Area, Australia should be leading the international efforts to reduce emissions, especially following the latest IPCC [Intergovernmental Panel on Climate Change] report. Our current commonwealth government has officially signed on to the 1.5-degree C target [for limiting global temperature rise] of the Paris agreement, but Australia’s emissions are actually increasing.

How will the loss of funding from the Australian Research Council affect your work?

It’s roughly a quarter of our funding and it won’t take effect for another two to three years, so we’ve got time to continue with our current level of activity and to change our funding model by moderate amounts to make up that loss. It’s not good news, certainly. But we will continue to do the research that we’re doing, especially if we see bleaching next year.

What do people misunderstand about the Great Barrier Reef?

There are still about 10 billion corals out there alive and kicking. We’ve just gone through one hell of a natural selection event where the so-called losers—the heat-susceptible species—have been badly depleted. The mix of species has changed. The genetic composition of the coral populations is changing. I think that is just the beginning of a transition that hopefully will make the Great Barrier Reef tougher for inevitable future events. Things will generally get worse before they get better. Until CO2 emissions and temperatures stabilize, the corals are going to be in for a rough ride. Because corals have big populations that are geographically widely dispersed, there is light at the end of the tunnel—but it is completely contingent on whether we can keep temperatures to the 1.5-degree C target.

====== 6 ========

HAVE ASTRONOMERS FOUND ANOTHER "ALIEN MEGASTRUCTURE" STAR?

A faraway star in the southern sky is flickering in an odd manner that suggests a bizarre cloud of material—or something even stranger—is in orbit around it. Discovered by astronomers using a telescope in Chile, the star is reminiscent of two other enigmatic astrophysical objects, one thought to harbor a planet with rings 200 times larger than those of Saturn, the other most famous for the remote possibility it is encircled by “alien megastructures.” The newfound star may help shed some light on one or both of these puzzling objects.

In 2010, the Vista Variables in the Via Lactea (VVV) survey began its project of creating a three-dimensional map of variable stars in the vicinity of the Milky Way’s center. As part of the project, astronomer Roberto Saito of the Federal University of Santa Catarina scoured the telescope’s data for eruptive outbursts from the hundreds of millions of monitored stars. But the most notable thing he found was not an outburst at all—it was a star that grew mysteriously dim over several days in 2012. He and his colleagues reported their findings in a recently published paper in the Monthly Notices of the Royal Astronomical Society.

Known as VVV-WIT-07, the star appears to be much older and redder than our sun, although the amount of interstellar dust between our solar system and the star’s home closer to the galactic center makes exact classification and distance measurements very difficult. What is certain is that in the summer of 2012, the object's brightness faded slightly for 11 days, then plummeted over the following 48 days, suggesting that something blocked more than three quarters of the star’s light streaming toward Earth. But what could that “something” be?

According to Eric Mamajek, an astrophysicist at the University of Rochester unaffiliated with the VVV survey, such a profound degree of dimming suggests that a staggeringly large object or group of objects is blocking the light. “It's got to be over a million kilometers wide, and very dense to be able to block that much starlight,” he says. Mamajek should know: He led the team that discovered J1407, another strange star periodically eclipsed by a planet-sized object thought to boast a massive ring system some 200 times broader than that of Saturn. In this latest case, he says, the strange signals from VVV-WIT-07 could arise from clumps or clouds of material passing between Earth and the star, though he cautioned that the data were preliminary and more observations are required.

Tabetha Boyajian agrees. Boyajian, an astronomer at Louisiana State University, was the lead author for the 2015 paper announcing the strange dimming of KIC 8462852, also known as Tabby's Star, an unusual object first spotted by NASA's Kepler Space Telescope. VVV-WIT-07 would have to harbor “a very peculiar kind of dust cloud to make these kinds of dips,” Boyajian says. Boyajian’s study helped spark a surge of public interest in Tabby’s Star because the star’s unusual dimming could be seen as evidence of an alien civilization building an artificial structure that soaked up the star’s light. More conventional explanations include a swarm of comets or fragments from a shattered planet, both of which would create significant clouds of dust and debris that could also occlude the star’s light. But, so far, no simple single explanation fits the complexities of the dimming seen around the star; researchers remain stymied in their attempts to understand the true nature of the strange dimming of Tabby’s Star.

Astronomers track such dips by plotting the intensity of a star’s light over time, a figure known as a “light curve.” The light curve of J1407 shows its massive rings can occasionally block as much as about 95 percent of the star’s light, while the light curve of Tabby's Star suggests that whatever orbits there only occludes about 20 percent of that star’s luminous emission. That makes VVV-WIT-07 an intermediate case, Saito says. “Our object is similar in the sense that we are also trying to explain the behavior in the light curve based on material surrounding the star,” he says.

Based on their data, including follow-up observations made in 2016, Saito and his colleagues speculate that the star may continue to flicker into 2019, potentially displaying four additional dimming events throughout the year as the mysterious light-blocking material continues its orbit around the star. If those predictions are borne out, they could prove key to unlocking not only the mysteries behind VVV-WIT-07 but also those surrounding Tabby’s Star.

“Having a sample of two, we can have two stars to study instead of one to try to unify a theory of whatever is going on,” Boyajian says. If both stellar dimmings are caused by the same natural process, it makes it less likely that something unusual is happening—like supersized cosmic construction projects.

There is hope that more of these peculiar flickering stars may show up in the near future. Saito says that it is possible the VVV survey could discover more, even though it is not optimized for identifying such systems. The Large Synoptic Survey Telescope (LSST), an 8.4-meter instrument under construction in Chile, could up turn up more members of the odd collection when it begins operations in the 2020s.

“I think we’re going to start finding more objects like this in the LSST era,” Mamajek says. “We’re probably going to start discovering weird variable [stars] that have not been seen before.”

For now, Saito and his colleagues plan to continue observing VVV-WIT-07 with infrared instruments on the ESO's New Technology Telescope and the National Optical Astronomy Observatory's Southern Astrophysical Research Telescope, both of which contributed to the team’s 2016 observations. The star’s intrinsic faintness—as well as the attenuation of its light across vast galactic distances—means that it is best observed at near-infrared wavelengths where interference from interstellar dust is minimal. Although the VVV Survey concluded last year, an extended survey is still observing the galactic center and may turn up other eclipses missed in the initial observations.

Hopefully these observations will shed some light on what is causing the bizarre dimming of VVV-WIT-07. “This is certainly not a common phenomenon,” Mamajek says. “I can't wait to see the future results.”

====== 7 ========

THE MILKY WAY’S CENTRAL BLACK HOLE IS A HOT SPOT FOR ASTROPHYSICS

The discovery of wobbling “hotspots” circling the drain of a massive black hole offers exciting new evidence for the behemoth that lies at our galaxy’s center—and the study leader shares how 13 years of observations have finally paid off.

The new study, led by Avery Broderick, an astronomer from the University of Waterloo in Ontario, Canada, revealed three flares, or visual hotspots, emanating from the Milky Way’s central black hole, also known as Sagittarius A*.

The team detected a wobble of emissions coming from the flares, allowing the scientists to detect the accretion disk—a growing mass of orbiting gas and debris—surrounding the black hole itself. In turn, the researchers were able to use the emissions to map the behavior of Sagittarius A*, Broderick told Space.com. [Images: Black Holes of the Universe]

Broderick’s work builds on earlier research by two teams that studied the galactic center of the Milky Way in near-infrared. This included the work of Reinhard Genzel, an astronomer from the Max Planck Institute for Extraterrestrial Physics in Garching, Germany, as well as researchers Andrea Ghez and Mark Morris of University of California, Los Angeles. At the time, their work revealed that the center of the Milky Way wasn’t steady, but instead would drastically brighten about once a day for about 30 or 40 minutes, Broderick said.

Researchers think supermassive black holes exist at the center of most, if not all, large galaxies. Therefore, in 2005, while working alongside researcher Avi Loeb at the Harvard-Smithsonian Center for Astrophysics, Broderick argued that a periodic brightening observed at the heart of the Milky Way, also known as a bright infrared flare, was the result of an incredibly massive object such as a black hole.

This theory was further supported by evidence of a very bright, dense group of stars called a nuclear star cluster that surrounds the central region of the Milky Way. In addition, infrared observations showed that the stars at the very center of the galaxy orbit a dark object estimated to be 4 million solar masses in size, again suggesting the presence of a black hole, Broderick said.

Even still, there was not enough data to prove that a black hole truly exists at the center of the Milky Way, Broderick added—until now.

Sudden flare behavior

The three flares Broderick’s team recently detected emanate from the central region of the Milky Way and are the product of gravitational lensing by the black hole, Broderick said.

“The black hole acts like the lens of a lighthouse. [There is] a localized emission region, but it’s not the sudden brightening of the emission region itself that causes the flare,” Broderick said. Rather, the gravity of the black hole bends the light from the emission and magnifies it for us to see. “That’s what’s responsible for the flaring—the manifestation of extreme gravity.”

Based on this, Broderick and Loeb originally predicted that objects embedded in the accretion disk surrounding Sagittarius A* would exhibit a distinct wobble in their infrared emissions due to their orbital motion around the black hole. The researchers published their theory in a 2005 paper, as well as a 2006 follow-up study. However, at the time, the technology was not yet available to detect such a wobble, Broderick said.

That all changed with the launch of the GRAVITY instrument on the European Southern Observatory’s Very Large Telescope in 2016. The precision and sensitivity of the GRAVITY instrument helped astronomers detect a wobble in emissions coming from the three flares in the accretion disk circling Sagittarius A*. Their findings were published Oct. 18 in the journal Astronomy & Astrophysics.

“While flares have been seen for a long time now… the key finding here is the characteristic wobble of the flares,” which indicates that the material producing these flares is moving around a black hole, Broderick said.

The flares observed near Sagittarius A* occur when magnetic field lines close to the black hole break apart and reconnect. This process, also known as magnetic reconnection, releases large amounts of energy and charged particles, causing the telltale shine. The infrared emissions from the flares exhibit a characteristic wobble due to their orbital motion around the black hole. Specifically, as other emissions embedded in the accretion flow move around the galactic center, the center of light shifts, or “wobbles,” Broderick said.

The material circling just outside the black hole’s event horizon whirls at roughly a third of the speed of light. The orbital period of the flare—the time it takes to complete one orbit—is the same as that of the wobble, which astronomers observed once every 40 to 50 minutes. The short time scale is a result of the strength of gravity from the black hole and suggests that the material is orbiting incredibly close to the black hole, Broderick said.

“Thirteen years ago, our statement was that these flares were associated with the structural variability [of the galactic center] and that we were going to be able to use that structural variability to say something about general relativityand strong gravity,” Broderick said. “The exciting thing is, that [statement] appears to be true.”

Proving there’s a black hole

The wobble of emissions coming from the flares is not the only sign suggesting that a supermassive black hole lies at the heart of the Milky Way. There’s no doubt that a supermassive object with a mass about 4 million times that of the sun is located at our galactic core, but proving that it’s a black hole has been challenging.

However, the center of the galaxy is also home to a nuclear star cluster comprising more than 500,000 stars. Based on Albert Einstein’s theory of general relativity, astronomers are able to estimate the mass of the object lurking at the center of the Milky Way by measuring the speed of the orbiting stars and gas. This further supports the idea that the 4-million-solar-mass object is a supermassive black hole, Broderick said.

“There is no other object that we know of that could sustain all of that mass in such a compact configuration and not collapse,” Broderick said. “If not a black hole, then it would have to be something extraordinarily exotic and outside the realm of what we understand today.”

Furthermore, observations have revealed that material really does disappear from our galactic center. As this material is drawn inward toward that center, it gets trapped in the black hole’s growing accretion disk. While most matter in the accretion disk orbits safely around Sagittarius A*, material that gets too close risks being drawn past the event horizon, the point beyond which it can’t escape the black hole’s gravitational pull. Researchers can see friction created by the material flowing toward the event horizon causing that material to brighten, Broderick said.

“It becomes this sort of ’where did it go?’ argument,” Broderick said. “We have this material that we know is falling in towards a black hole, because we see its accretion luminosity, but we don’t see the corresponding impact luminosity. Therefore, it must be disappearing somewhere.”

The presence of an event horizon beyond which lies a black hole is therefore the most logical explanation for the behavior observed at our galactic center, Broderick said.

“It’s extremely exciting on a personal level to see a prediction actually pan out,” Broderick said. “I think this marks a moment in the history of science, where black holes are going from something of curiosity to something that is fundamentally real.”

Copyright 2018 Space.com, a Future company. All rights reserved. This material may not be published, broadcast, rewritten or redistributed.

====== 8 ========

DO YOU NEED TO TAKE DIGESTIVE ENZYMES?

Melissa writes: “I’ve heard that as you age the amount of digestive enzymes your body produces decreases making it more difficult to digest your food. So you end up with symptoms like excessive belching, bloating, gas. Some people recommend taking digestive enzyme supplements with each meal. Is this information correct? How and when should you use digestive enzyme supplements if at all?”

Over-the-counter digestive enzymes supplements have grown increasingly popular and are marketed to help with digestive symptoms like indigestion, bloating, and gas. But can these supplements really help you digest your food better or relieve these symptoms?

What Are Digestive Enzymes?

»Continue reading “Do You Need to Take Digestive Enzymes?” on QuickAndDirtyTips.com

====== 9 ========

THE HUNT FOR SKY’S “DETERGENT” BEGINS IN ANTARCTICA

To understand how the sky cleanses itself, a team of Australian and US researchers is heading to Antarctica to track down the atmosphere’s main detergent. By drilling deep into polar ice, the scientists hope to determine how the sky’s capacity to scrub away some ozone-depleting chemicals and potent greenhouse gases has changed since the Industrial Revolution—information that could help to improve global-warming projections.

The first members of the project travelled to Law Dome, their drilling site in East Antarctica, this week. There, they hope to capture the first historical data on concentrations of the dominant atmospheric detergent, the hydroxyl radical. This highly reactive molecule, made of an oxygen atom bonded to a hydrogen atom, breaks down about 40 gases in the air. They include methane and hydrofluorocarbons, but not the most prevalent greenhouse gas—carbon dioxide.

Although studies of other atmospheric gases have been used to infer the abundance of hydroxyl over the past four decades, atmospheric chemists still refer to the chemical as ‘the great unknown’.

“We have been more or less in the dark when it comes to how hydroxyl has evolved from pre-industrial times to present day,” says Apostolos Voulgarakis, an environmental scientist at Imperial College London. “This new research endeavour can provide unprecedented information on hydroxyl variations in the deeper past, which is exciting.”

Risky business

Over two and a half months, the team will drill at least two ice cores—three if time allows—down to depths of about 230 metres. They will then melt the cores to extract bubbles of air that were trapped as the ice froze. The samples will represent the atmosphere back to about 1880, before emissions of greenhouse gases from human activity started to increase.

Hydroxyl radicals form naturally in the atmosphere in a reaction involving ultraviolet rays, ozone and water vapour. But because the radicals last about a second before they react with other gases and break them down, as a proxy, the team will instead measure the tiny fraction of carbon monoxide that contains the carbon-14 isotope.

Carbon-14 in carbon monoxide is produced in the atmosphere by cosmic rays at a known rate, and is almost entirely removed by hydroxyl. Because of this, scientists can use the trend in its abundance to infer the trend of the radical, says David Etheridge, an atmospheric chemist at the Commonwealth Scientific and Industrial Research Organisation (CSIRO) in Aspendale, Australia, and a co-leader of the drilling project.

But measuring levels of carbon monoxide that contain carbon-14 is tricky, because there are only a few kilograms of it in the atmosphere, says Etheridge. “And we’re trying to measure a bit of that over the last 150 years in the Antarctic ice.”

There is also a risk that the ice cores will become contaminated with external sources of carbon-14 from cosmic rays. This high-energy radiation cannot penetrate the ice, but the moment the cores are removed, they are at risk of exposure. This would interfere with the signal the team is trying to measure, says co-leader Vasilii Petrenko, an ice-core scientist at the University of Rochester in New York. To avoid that risk, the researchers will melt the ice and extract the air on-site.

A long haul

Organizing the equipment to do this and transport it to a remote ice sheet has been a huge logistical challenge, says team member Peter Neff, an ice-core scientist at the University of Washington in Seattle.

Tractors pulled giant sleds loaded with equipment to the Law Dome drilling site, which is more than 130 kilometres from the nearest research station. And it will take the team 36 days to melt the ice they need to get enough air samples. “It's a marathon, not a sprint,” says Neff.

The project is co-funded by the Australian Antarctic Division and the US National Science Foundation.

Once the researchers return from Antarctica, to assess the levels of the carbon-14 in carbon monoxide, the team will convert the gas into carbon dioxide and then into graphite, from which the isotope can be measured. The scientists can then use the information to infer how hydroxyl levels in the Southern Hemisphere have changed over time.

Model improvement

Up to now, information on historical trends in hydroxyl levels has come solely from atmospheric models; these simulations suggest that concentrations remained fairly stable from 1850 until the 1970s, when they started to rise. The increase was mainly because of a boost in atmospheric warming at the time, says Voulgarakis.

The data collected from Law Dome will help to determine whether the atmospheric models have captured this trend correctly, says Matt Woodhouse, a climate modeller at CSIRO, who will use the information to improve Australia’s global chemistry-climate model, called ACCESS. “Our ability to resolve hydroxyl won’t revolutionize climate models, but it’ll increase our confidence in them.”

And accurate pictures of hydroxyl’s historical and current atmospheric concentrations are essential for developing better projections of its future levels, says Voulgarakis. This will then enable more-accurate projections of the future abundance of gases that affect climate—such as methane, ozone in the lowest layer of the atmosphere, and aerosols—that hydroxyl scrubs from the sky, he says. This would make it easier to determine the gases’ potential contribution to global warming.

This article is reproduced with permission and was first published on November 20, 2018.

====== 10 ========

ARTISTS STRIVE TO MAKE CLIMATE IMPACTS “VISCERAL”

A new art installation by British artist and filmmaker John Akomfrah that focuses on climate change will open in the Boston Harbor next spring.

"Purple" is an immersive six-channel video installation that sheds light on climate change's effects on human communities, biodiversity and the wilderness, according to a news release. The film will be shown from May 26 through Sept. 2, 2019, at the Boston Harbor Shipyard and Marina in East Boston.

Akomfrah, who was recently named next year's resident artist by the Institute of Contemporary Art/Boston Watershed, is among a growing movement of artists around the world who are using art to bring a sense of awareness and urgency to the potentially catastrophic impacts of climate change.

Although climate art is a relatively new concept, it's starting to change the conversation people have about climate change, said Miranda Massie, the director of the Climate Museum, a nonprofit that's aiming to build a physical museum dedicated to climate change in New York City.

"There's now a burgeoning body of work in the climate art field across the artistic disciplines and media," Massie said.

However, she added that it is premature to say that climate-focused artists have had any robust impact on policy discussion. But she sees it growing in the near future.

"As climate art starts to move the cultural shift on climate, we will see it have a policy impact," Massie said.

The movement has also shown that artists and scientists can effectively collaborate and often share their respective skill sets to better communicate about climate change.

Julia Levine, artistic producer at the Arctic Cycle, said the scientists she knows have often collaborated with artists as a way to translate and make the immediacy of climate change more tangible and visual.

She added that although hard data can be understood by some, it is also important to reach the masses by other means — whether that's through images or storytelling.

Massie said that one of the reasons communicating the risks presents such a huge challenge is that even in the middle of a hurricane, climate change still feels abstract to some.

"For people who are not scientifically trained, the data points on a graph don't have real emotional visceral meaning," Massie said. "Artists make things visceral and make us feel things emotionally and physically, and that's critically important for climate change."

In "Purple," Akomfrah used archival footage and newly shot films from 10 countries. The video installation is divided into five interwoven movements, which feature various disappearing ecological landscapes, including the hinterlands of Alaska, the desolate environments of Greenland, the Tahitian peninsula and the volcanic Marquesas Islands in the South Pacific.

"I'm an artist. I make work for a gallery. I'm not attempting to make a science documentary. I'm coming at it from a different perspective by asking the question: What is philosophically, ethically and morally at stake here if we continue on this course?" Akomfrah told the London Guardian in October 2017.

Akomfrah was born in Ghana but lives and works in London. He is a founding member of the film and television production company Smoking Dogs Films. His work has been shown in museums and exhibitions around the world, including New York's Museum of Modern Art, the New Museum, and the Eli and Edythe Broad Art Museum.

"What astounds me about the art of John Akomfrah is that the beauty, power, and grace of his work conveys a sense of the sublime and the possible, despite its depiction of the powerful impacts of climate change, rising sea levels, and the increase of severe weather," Jill Medvedow, director of the Boston Institute of Contemporary Art, said in the news release.

"'Purple' embodies the belief that inward reflection must be paired with active engagement," Medvedow added.

George Mason University professor Edward Maibach, who focuses on climate change communication, said in an email that art and popular culture can have a big impact on the way people perceive and engage in climate change.

"Artists typically strive to make people feel, while scientists typically strive to make people think," Maibach said.

However, he said, artists shouldn't be solely responsible for bringing up the issue.

"Artists won't solve this problem for us," he said, "but we may not be able to solve it without them either."

Reprinted from Climatewire with permission from E&E News. E&E provides daily coverage of essential energy and environmental news at www.eenews.net.

====== 11 ========

SILENT AND SIMPLE ION ENGINE POWERS A PLANE WITH NO MOVING PARTS

Behind a thin white veil separating his makeshift lab from joggers at a Massachusetts Institute of Technology indoor track, aerospace engineer Steven Barrett recently test-flew the first-ever airplane powered with ionic wind thrusters—electric engines that generate momentum by creating and firing off charged particles.

Using this principle to fly an aircraft has long been, according even to Barrett, a “far-fetched idea” and the stuff of science fiction. But he still wanted to try. “In Star Trek you have shuttlecraft gliding silently past,” he says. “I thought, ‘We should have aircraft like that.’”

Thinking ionic wind propulsion could fit the bill, he spent eight years studying the technology and then decided to try building a prototype miniature aircraft—albeit one he thought was a little ugly. “It’s a kind of dirty yellow color,” he says, adding that black paint often contains carbon—which conducts electricity and caused a previous iteration to fry itself.

Barrett had slightly higher hopes for the latest prototype, which he dispassionately named Version 2. “Before we started the test flights I thought it had maybe a 50–50 chance,” he says. “My colleague at MIT thought it was more like a 1 percent chance it would work.”

Credit: MIT

But unlike its predecessors, which had tumbled to the ground, Version 2 sailed nearly 200 feet through the air at roughly 11 miles per hour (17 kilometers per hour). With no visible exhaust and no roaring jet or whirling propeller—no moving parts at all, in fact—the aircraft seemed silently animated by an ethereal source. “It was very exciting,” Barrett says. “Then it crashed into the wall, which wasn’t ideal.”

Still, Version 2 had worked, and Barrett and his colleagues published their results Wednesday in Nature. The flight was a feat others have tried but failed, says Mitchell Walker, an aerospace engineer at Georgia Institute of Technology who did not work on the new plane. “[Barrett] has demonstrated something truly unique,” he says. Ion thrusters are not a particularly new technology; they already help push spacecraft very efficiently—but they are a far cry from rockets or jets, and normally nudge spacecraft into place in orbit. They have also propelled deep-space probes such as Dawn on missions to the Asteroid Belt. In the near-vacuum of space, ion thrusters have to carry an onboard supply of gas that they ionize and fire off into the relative emptiness to create thrust. When it comes to moving through Earth’s thick atmosphere, however, “everyone saw that the velocity [from an ion thruster] was not sufficient for propelling an aircraft,” Walker says. “Nobody understood how to go forward.”

But Barrett and his team figured out three main things to make Version 2 work. The first was the ionic wind thruster design. Version 2’s thrusters consist of two rows of long metal strands draped under its sky blue wings. The front row conducts some 40,000 volts of electricity—166 times the voltage delivered to the average house, and enough energy to strip the electrons off ample nitrogen atoms hanging in the atmosphere.

When that happens, the nitrogen atoms turn into positively charged ions. Because the back row of metal filaments carries a negative charge, the ions careen toward it like magnetized billiard balls. “Along the way, there are millions of collisions between these ions and neutral air molecules,” Barrett notes. That shoves the air molecules toward the back of the plane, creating a wind that pushes the plane forward fast and hard enough to fly.

Another innovation Barrett’s team came up with was designing a lightweight but powerful electrical system, Walker notes. Before this aircraft, he says, nobody had created a system that could convert power from a lightweight battery efficiently enough to generate sufficient voltage for the thrusters. “The biggest challenge is [ion thrusters] need 20,000 or 30,000 volts just to work. High voltage on an aircraft doesn’t come easy,” he says. “You want to play with 40,000 volts on an aircraft? That technology didn’t exist. Steve [Barrett] found a clever way to get that efficient conversion.”

Finally Barrett used a computer model to get the most out of every design element in the aircraft, from the thruster and electrical system designs to the wires that ran through the plane. “The power converter, the battery, the caps and fuselage—everything was optimized,” Barrett says. “The simulations failed all the time. We had to make hundreds of changes.” In the end, they had the triumphant Version 2.

The breakthrough offers a great proof of concept showing ion thrusters can be used on Earth, says Alec Gallimore, an aerospace engineer at the University of Michigan who was not involved with the work. But any such use would likely be in limited capacities. Propellers and jets are still far more efficient than the ion wind thrusters Barrett demonstrated, making it unlikely that passenger planes would switch over anytime soon. But the thrusters have one key advantage: “There’s no sound generation. So [drones] for building inspections or things like that” would be an ideal application for these thrusters, Gallimore notes.

Or, Barrett adds, drones used for deliveries, filming or environmental monitoring. “Imagine 10 or 20 years from now—we could have drones everywhere,” he says. “If those are all noisy, they’ll degrade our quality of life. But this is silent.”

====== 12 ========

THE AMERICAN ECONOMY IS RIGGED

Americans are used to thinking that their nation is special. In many ways, it is: the U.S. has by far the most Nobel Prize winners, the largest defense expenditures (almost equal to the next 10 or so countries put together) and the most billionaires (twice as many as China, the closest competitor). But some examples of American Exceptionalism should not make us proud. By most accounts, the U.S. has the highest level of economic inequality among developed countries. It has the world's greatest per capita health expenditures yet the lowest life expectancy among comparable countries. It is also one of a few developed countries jostling for the dubious distinction of having the lowest measures of equality of opportunity.

The notion of the American Dream—that, unlike old Europe, we are a land of opportunity—is part of our essence. Yet the numbers say otherwise. The life prospects of a young American depend more on the income and education of his or her parents than in almost any other advanced country. When poor-boy-makes-good anecdotes get passed around in the media, that is precisely because such stories are so rare.

Things appear to be getting worse, partly as a result of forces, such as technology and globalization, that seem beyond our control, but most disturbingly because of those within our command. It is not the laws of nature that have led to this dire situation: it is the laws of humankind. Markets do not exist in a vacuum: they are shaped by rules and regulations, which can be designed to favor one group over another. President Donald Trump was right in saying that the system is rigged—by those in the inherited plutocracy of which he himself is a member. And he is making it much, much worse.

America has long outdone others in its level of inequality, but in the past 40 years it has reached new heights. Whereas the income share of the top 0.1 percent has more than quadrupled and that of the top 1 percent has almost doubled, that of the bottom 90 percent has declined. Wages at the bottom, adjusted for inflation, are about the same as they were some 60 years ago! In fact, for those with a high school education or less, incomes have fallen over recent decades. Males have been particularly hard hit, as the U.S. has moved away from manufacturing industries into an economy based on services.

Deaths of Despair

Wealth is even less equally distributed, with just three Americans having as much as the bottom 50 percent—testimony to how much money there is at the top and how little there is at the bottom. Families in the bottom 50 percent hardly have the cash reserves to meet an emergency. Newspapers are replete with stories of those for whom the breakdown of a car or an illness starts a downward spiral from which they never recover.

In significant part because of high inequality, U.S. life expectancy, exceptionally low to begin with, is experiencing sustained declines. This in spite of the marvels of medical science, many advances of which occur right here in America and which are made readily available to the rich. Economist Ann Case and 2015 Nobel laureate in economics Angus Deaton describe one of the main causes of rising morbidity—the increase in alcoholism, drug overdoses and suicides—as “deaths of despair” by those who have given up hope.

Credit: Jen Christiansen; Sources: “The Fading American Dream: Trends in Absolute Income Mobility since 1940,” by Raj Chetty et al., in Science, Vol. 356; April 28, 2017 (child-parent wealth comparison); World Inequality database (90% versus 1% wealth trend data)

Defenders of America's inequality have a pat explanation. They refer to the workings of a competitive market, where the laws of supply and demand determine wages, prices and even interest rates—a mechanical system, much like that describing the physical universe. Those with scarce assets or skills are amply rewarded, they argue, because of the larger contributions they make to the economy. What they get merely represents what they have contributed. Often they take out less than they contributed, so what is left over for the rest is that much more.

This fictional narrative may at one time have assuaged the guilt of those at the top and persuaded everyone else to accept this sorry state of affairs. Perhaps the defining moment exposing the lie was the 2008 financial crisis, when the bankers who brought the global economy to the brink of ruin with predatory lending, market manipulation and various other antisocial practices walked away with millions of dollars in bonuses just as millions of Americans lost their jobs and homes and tens of millions more worldwide suffered on their account. Virtually none of these bankers were ever held to account for their misdeeds.

I became aware of the fantastical nature of this narrative as a schoolboy, when I thought of the wealth of the plantation owners, built on the backs of slaves. At the time of the Civil War, the market value of the slaves in the South was approximately half of the region's total wealth, including the value of the land and the physical capital—the factories and equipment. The wealth of at least this part of this nation was not based on industry, innovation and commerce but rather on exploitation. Today we have replaced this open exploitation with more insidious forms, which have intensified since the Reagan-Thatcher revolution of the 1980s. This exploitation, I will argue, is largely to blame for the escalating inequality in the U.S.

After the New Deal of the 1930s, American inequality went into decline. By the 1950s inequality had receded to such an extent that another Nobel laureate in economics, Simon Kuznets, formulated what came to be called Kuznets's law. In the early stages of development, as some parts of a country seize new opportunities, inequalities grow, he postulated; in the later stages, they shrink. The theory long fit the data—but then, around the early 1980s, the trend abruptly reversed.

Explaining Inequality

Economists have put forward a range of explanations for why inequality has in fact been increasing in many developed countries. Some argue that advances in technology have spurred the demand for skilled labor relative to unskilled labor, thereby depressing the wages of the latter. Yet that alone cannot explain why even skilled labor has done so poorly over the past two decades, why average wages have done so badly and why matters are so much worse in the U.S. than in other developed nations. Changes in technology are global and should affect all advanced economies in the same way. Other economists blame globalization itself, which has weakened the power of workers. Firms can and do move abroad unless demands for higher wages are curtailed. But again, globalization has been integral to all advanced economies. Why is its impact so much worse in the U.S.?

The shift from a manufacturing to a service-based economy is partly to blame. At its extreme—a firm of one person—the service economy is a winner-takes-all system. A movie star makes millions, for example, whereas most actors make a pittance. Overall, wages are likely to be far more widely dispersed in a service economy than in one based on manufacturing, so the transition contributes to greater inequality. This fact does not explain, however, why the average wage has not improved for decades. Moreover, the shift to the service sector is happening in most other advanced countries: Why are matters so much worse in the U.S.?

Again, because services are often provided locally, firms have more market power: the ability to raise prices above what would prevail in a competitive market. A small town in rural America may have only one authorized Toyota repair shop, which virtually every Toyota owner is forced to patronize. The providers of these local services can raise prices over costs, increasing their profits and the share of income going to owners and managers. This, too, increases inequality. But again, why is U.S. inequality practically unique?

In his celebrated 2013 treatise Capital in the Twenty-First Century, French economist Thomas Piketty shifts the gaze to capitalists. He suggests that the few who own much of a country's capital save so much that, given the stable and high return to capital (relative to the growth rate of the economy), their share of the national income has been increasing. His theory has, however, been questioned on many grounds. For instance, the savings rate of even the rich in the U.S. is so low, compared with the rich in other countries, that the increase in inequality should be lower here, not greater.

An alternative theory is far more consonant with the facts. Since the mid-1970s the rules of the economic game have been rewritten, both globally and nationally, in ways that advantage the rich and disadvantage the rest. And they have been rewritten further in this perverse direction in the U.S. than in other developed countries—even though the rules in the U.S. were already less favorable to workers. From this perspective, increasing inequality is a matter of choice: a consequence of our policies, laws and regulations.

In the U.S., the market power of large corporations, which was greater than in most other advanced countries to begin with, has increased even more than elsewhere. On the other hand, the market power of workers, which started out less than in most other advanced countries, has fallen further than elsewhere. This is not only because of the shift to a service-sector economy—it is because of the rigged rules of the game, rules set in a political system that is itself rigged through gerrymandering, voter suppression and the influence of money. A vicious spiral has formed: economic inequality translates into political inequality, which leads to rules that favor the wealthy, which in turn reinforces economic inequality.

Feedback Loop

Political scientists have documented the ways in which money influences politics in certain political systems, converting higher economic inequality into greater political inequality. Political inequality, in its turn, gives rise to more economic inequality as the rich use their political power to shape the rules of the game in ways that favor them—for instance, by softening antitrust laws and weakening unions. Using mathematical models, economists such as myself have shown that this two-way feedback loop between money and regulations leads to at least two stable points. If an economy starts out with lower inequality, the political system generates rules that sustain it, leading to one equilibrium situation. The American system is the other equilibrium—and will continue to be unless there is a democratic political awakening.

An account of how the rules have been shaped must begin with antitrust laws, first enacted 128 years ago in the U.S. to prevent the agglomeration of market power. Their enforcement has weakened—at a time when, if anything, the laws themselves should have been strengthened. Technological changes have concentrated market power in the hands of a few global players, in part because of so-called network effects: you are far more likely to join a particular social network or use a certain word processor if everyone you know is already using it. Once established, a firm such as Facebook or Microsoft is hard to dislodge. Moreover, fixed costs, such as that of developing a piece of software, have increased as compared with marginal costs—that of duplicating the software. A new entrant has to bear all these fixed costs up front, and if it does enter, the rich incumbent can respond by lowering prices drastically. The cost of making an additional e-book or photo-editing program is essentially zero.

In short, entry is hard and risky, which gives established firms with deep war chests enormous power to crush competitors and ultimately raise prices. Making matters worse, U.S. firms have been innovative not only in the products they make but in thinking of ways to extend and amplify their market power. The European Commission has imposed fines of billions of dollars on Microsoft and Google and ordered them to stop their anticompetitive practices (such as Google privileging its own comparison shopping service). In the U.S., we have done too little to control concentrations of market power, so it is not a surprise that it has increased in many sectors.

Credit: Jen Christiansen; Sources: Economic Report of the President. January 2017; World Inequality database

Rigged rules also explain why the impact of globalization may have been worse in the U.S. A concerted attack on unions has almost halved the fraction of unionized workers in the nation, to about 11 percent. (In Scandinavia, it is roughly 70 percent.) Weaker unions provide workers less protection against the efforts of firms to drive down wages or worsen working conditions. Moreover, U.S. investment treaties such as the North Atlantic Free Trade Agreement—treaties that were sold as a way of preventing foreign countries from discriminating against American firms—also protect investors against a tightening of environmental and health regulations abroad. For instance, they enable corporations to sue nations in private international arbitration panels for passing laws that protect citizens and the environment but threaten the multinational company's bottom line. Firms like these provisions, which enhance the credibility of a company's threat to move abroad if workers do not temper their demands. In short, these investment agreements weaken U.S. workers' bargaining power even further.

Liberated Finance

Many other changes to our norms, laws, rules and regulations have contributed to inequality. Weak corporate governance laws have allowed chief executives in the U.S. to compensate themselves 361 times more than the average worker, far more than in other developed countries. Financial liberalization—the stripping away of regulations designed to prevent the financial sector from imposing harms, such as the 2008 economic crisis, on the rest of society—has enabled the finance industry to grow in size and profitability and has increased its opportunities to exploit everyone else. Banks routinely indulge in practices that are legal but should not be, such as imposing usurious interest rates on borrowers or exorbitant fees on merchants for credit and debit cards and creating securities that are designed to fail. They also frequently do things that are illegal, including market manipulation and insider trading. In all of this, the financial sector has moved money away from ordinary Americans to rich bankers and the banks' shareholders. This redistribution of wealth is an important contributor to American inequality.

Other means of so-called rent extraction—the withdrawal of income from the national pie that is incommensurate with societal contribution—abound. For example, a legal provision enacted in 2003 prohibited the government from negotiating drug prices for Medicare—a gift of some $50 billion a year or more to the pharmaceutical industry. Special favors, such as extractive industries' obtaining public resources such as oil at below fair-market value or banks' getting funds from the Federal Reserve at near-zero interest rates (which they relend at high interest rates), also amount to rent extraction. Further exacerbating inequality is favorable tax treatment for the rich. In the U.S., those at the top pay a smaller fraction of their income in taxes than those who are much poorer—a form of largesse that the Trump administration has just worsened with the 2017 tax bill.

Some economists have argued that we can lessen inequality only by giving up on growth and efficiency. But recent research, such as work done by Jonathan Ostry and others at the International Monetary Fund, suggests that economies with greater equality perform better, with higher growth, better average standards of living and greater stability. Inequality in the extremes observed in the U.S. and in the manner generated there actually damages the economy. The exploitation of market power and the variety of other distortions I have described, for instance, makes markets less efficient, leading to underproduction of valuable goods such as basic research and overproduction of others, such as exploitative financial products.

Credit: Jen Christiansen; Sources: World Inequality Report 2018. World Inequality Lab, 2017; Branko Milanovic

Moreover, because the rich typically spend a smaller fraction of their income on consumption than the poor, total or “aggregate” demand in countries with higher inequality is weaker. Societies could make up for this gap by increasing government spending—on infra-structure, education and health, for instance, all of which are investments necessary for long-term growth. But the politics of unequal societies typically puts the burden on monetary policy: interest rates are lowered to stimulate spending. Artificially low interest rates, especially if coupled with inadequate financial market regulation, can give rise to bubbles, which is what happened with the 2008 housing crisis.

It is no surprise that, on average, people living in unequal societies have less equality of opportunity: those at the bottom never get the education that would enable them to live up to their potential. This fact, in turn, exacerbates inequality while wasting the country's most valuable resource: Americans themselves.

Restoring Justice

Morale is lower in unequal societies, especially when inequality is seen as unjust, and the feeling of being used or cheated leads to lower productivity. When those who run gambling casinos or bankers suffering from moral turpitude make a zillion times more than the scientists and inventors who brought us lasers, transistors and an understanding of DNA, it is clear that something is wrong. Then again, the children of the rich come to think of themselves as a class apart, entitled to their good fortune, and accordingly more likely to break the rules necessary for making society function. All of this contributes to a breakdown of trust, with its attendant impact on social cohesion and economic performance.

There is no magic bullet to remedy a problem as deep-rooted as America's inequality. Its origins are largely political, so it is hard to imagine meaningful change without a concerted effort to take money out of politics—through, for instance, campaign finance reform. Blocking the revolving doors by which regulators and other government officials come from and return to the same industries they regulate and work with is also essential.

Credit: Jen Christiansen; Sources: Raising America’s Pay: Why It’s Our Central Economic Policy Challenge, by Josh Bivens et al. Economic Policy Institute, June 4, 2014; The State of Working America, by Lawrence Mishel, Josh Bivens, Elise Gould and Heidi Shierholz. 12th Edition. ILR Press, 2012

Beyond that, we need more progressive taxation and high-quality federally funded public education, including affordable access to universities for all, no ruinous loans required. We need modern competition laws to deal with the problems posed by 21st-century market power and stronger enforcement of the laws we do have. We need labor laws that protect workers and their rights to unionize. We need corporate governance laws that curb exorbitant salaries bestowed on chief executives, and we need stronger financial regulations that will prevent banks from engaging in the exploitative practices that have become their hallmark. We need better enforcement of antidiscrimination laws: it is unconscionable that women and minorities get paid a mere fraction of what their white male counterparts receive. We also need more sensible inheritance laws that will reduce the intergenerational transmission of advantage and disadvantage.

The basic perquisites of a middle-class life, including a secure old age, are no longer attainable for most Americans. We need to guarantee access to health care. We need to strengthen and reform retirement programs, which have put an increasing burden of risk management on workers (who are expected to manage their portfolios to guard simultaneously against the risks of inflation and market collapse) and opened them up to exploitation by our financial sector (which sells them products designed to maximize bank fees rather than retirement security). Our mortgage system was our Achilles' heel, and we have not really fixed it. With such a large fraction of Americans living in cities, we have to have urban housing policies that ensure affordable housing for all.

It is a long agenda—but a doable one. When skeptics say it is nice but not affordable, I reply: We cannot afford to not do these things. We are already paying a high price for inequality, but it is just a down payment on what we will have to pay if we do not do something—and quickly. It is not just our economy that is at stake; we are risking our democracy.

As more of our citizens come to understand why the fruits of economic progress have been so unequally shared, there is a real danger that they will become open to a demagogue blaming the country's problems on others and making false promises of rectifying “a rigged system.” We are already experiencing a foretaste of what might happen. It could get much worse.

====== 13 ========

"SCHRÖDINGER'S BACTERIUM" COULD BE A QUANTUM BIOLOGY MILESTONE

The quantum world is a weird one. In theory and to some extent in practice its tenets demand that a particle can appear to be in two places at once—a paradoxical phenomenon known as superposition—and that two particles can become “entangled,” sharing information across arbitrarily large distances through some still-unknown mechanism.

Perhaps the most famous example of quantum weirdness is Schrödinger’s cat, a thought experiment devised by Erwin Schrödinger in 1935. The Austrian physicist imagined how a cat placed in a box with a potentially lethal radioactive substance could, per the odd laws of quantum mechanics, exist in a superposition of being both dead and alive—at least until the box is opened and its contents observed.

As far-out as that seems, the concept has been experimentally validated countless times on quantum scales. Scaled up to our seemingly simpler and certainly more intuitive macroscopic world, however, things change. No one has ever witnessed a star, a planet or a cat in superposition or a state of quantum entanglement. But ever since quantum theory’s initial formulation in the early 20th century, scientists have wondered where exactly the microscopic and macroscopic worlds cross over. Just how big can the quantum realm be, and could it ever be big enough for its weirdest aspects to intimately, clearly influence living things? Across the past two decades the emergent field of quantum biology has sought answers for such questions, proposing and performing experiments on living organisms that could probe the limits of quantum theory.

Those experiments have already yielded tantalizing but inconclusive results. Earlier this year, for example, researchers showed the process of photosynthesis—whereby organisms make food using light—may involve some quantum effects. How birds navigate or how we smell also suggest quantum effects may take place in unusual ways within living things. But these only dip a toe into the quantum world. So far, no one has ever managed to coax an entire living organism—not even a single-celled bacterium—into displaying quantum effects such as entanglement or superposition.

So a new paper from a group at the University of Oxford is now raising some eyebrows for its claims of the successful entanglement of bacteria with photons—particles of light. Led by the quantum physicist Chiara Marletto and published in October in the Journal of Physics Communications, the study is an analysis of an experiment conducted in 2016 by David Coles from the University of Sheffield and his colleagues. In that experiment Coles and company sequestered several hundred photosynthetic green sulfur bacteria between two mirrors, progressively shrinking the gap between the mirrors down to a few hundred nanometers—less than the width of a human hair. By bouncing white light between the mirrors, the researchers hoped to cause the photosynthetic molecules within the bacteria to couple—or interact—with the cavity, essentially meaning the bacteria would continuously absorb, emit and reabsorb the bouncing photons. The experiment was successful; up to six bacteria did appear to couple in this manner.

Marletto and her colleagues argue the bacteria did more than just couple with the cavity, though. In their analysis they demonstrate the energy signature produced in the experiment could be consistent with the bacteria’s photosynthetic systems becoming entangled with the light inside the cavity. In essence, it appears certain photons were simultaneously hitting and missing photosynthetic molecules within the bacteria—a hallmark of entanglement. “Our models show that this phenomenon being recorded is a signature of entanglement between light and certain degrees of freedom inside the bacteria,” she says.

According to study co-author Tristan Farrow, also of Oxford, this is the first time such an effect has been glimpsed in a living organism. “It certainly is key to demonstrating that we are some way toward the idea of a ‘Schrödinger’s bacterium,’ if you will,” he says. And it hints at another potential instance of naturally emerging quantum biology: Green sulfur bacteria reside in the deep ocean where the scarcity of life-giving light might even spur quantum-mechanical evolutionary adaptations to boost photosynthesis.

There are many caveats to such controversial claims, however. First and foremost, the evidence for entanglement in this experiment is circumstantial, dependent on how one chooses to interpret the light trickling through and out of the cavity-confined bacteria. Marletto and her colleagues acknowledge a classical model free of quantum effects could also account for the experiment’s results. But, of course, photons are not classical at all—they are quantum. And yet a more realistic “semiclassical” model using Newton’s laws for the bacteria and quantum ones for photons fails to reproduce the actual outcome Coles and his colleagues observed in their laboratory. This hints that quantum effects were at play in both the light and the bacteria. “It’s a little bit indirect, but I think it’s because they’re only trying to be so rigorous in ruling out things and claiming anything too much,” says James Wootton, a quantum computing researcher at IBM Zurich Research Laboratory who was not involved in either paper.

The other caveat: the energies of the bacteria and the photon were measured collectively, not independently. This, according to Simon Gröblacher of Delft University of Technology in the Netherlands who was not part of this research, is somewhat of a limitation. “There seems to be something quantum going on,” he says. “But…usually if we demonstrate entanglement, you have to measure the two systems independently” to confirm any quantum correlation between them is genuine.

Despite these uncertainties, for many experts, quantum biology’s transition from theoretical dream to tangible reality is a question of when, not if. In isolation and collectively, molecules outside of biological systems have already exhibited quantum effects in decades’ worth of laboratory experiments, so seeking out these effects for similar molecules inside a bacterium or even our own bodies would seem sensible enough. In humans and other large multicellular organisms, however, such molecular quantum effects should be averaged out to insignificance—but their meaningful manifestation within far smaller bacteria would not be too shocking. “I’m a little torn about how surprising [this finding] is,” Gröblacher says. “But it’s obviously exciting if you can show this in a real biological system.”

Several research groups, including those led by Gröblacher and Farrow, are hoping to take these ideas even further. Gröblacher has designed an experiment that could place a tiny aquatic animal called a tardigrade in superposition—a proposition much more difficult than entangling bacteria with light owing to a tardigrade’s hundreds-fold–larger size. Farrow is looking at ways to improve on the bacterial experiment; in the next year he and his colleagues hope to entangle two bacteria together, rather than independently with light. “The long-term goals are foundational and fundamental,” Farrow says. “This is about understanding the nature of reality, and whether quantum effects have a utility in biological functions. At the root of things, everything is quantum,” he adds, with the big question being whether quantum effects play a role in how living things work.

It might be, for example, that “natural selection has come up with ways for living systems to naturally exploit quantum phenomena,” Marletto notes, such as the aforementioned example of bacteria photosynthesizing in the light-starved deep sea. But getting to the bottom of this requires starting small. The research has steadily been climbing toward macrolevel experiments, with one recent experiment successfully entangling millions of atoms. Proving the molecules that make up living things exhibit meaningful quantum effects—even if for trivial purposes—would be a key next step. By exploring this quantum–classical boundary, scientists could get closer to understanding what it would mean to be macroscopically quantum, if such an idea is true.

Jonathan O'Callaghan is a freelance space and science journalist based in London. You can follow him on Twitter @Astro_Jonny.

====== 14 ========

PHOTONS, QUASARS AND THE POSSIBILITY OF FREE WILL

Life is full of choices. Do we have a cookie or go to the gym? Do we binge watch our favorite show on Netflix or go to bed at a reasonable time? Our choices have consequences, and we make them of our own free will. Or do we?

The nature of free will has long inspired philosophical debates, but it also raises a central question about the fundamental nature of the universe. Is the cosmos governed by strict physical laws that determine its fate from the big bang until the end of time? Or do the laws of nature sometimes allow for things to happen at random? A century-old series of physics experiments still hasn’t been able to settle the question, but a new experiment has tilted the odds toward the latter by performing a quantum experiment across billions of light-years.

The laws of classical physics are deterministic. Newton’s mathematical cosmos is a clockwork universe, where each cause has a unique effect and we are governed not by our choices but by the rigid laws of nature. Quantum physics, on the other hand, has a property of fuzzy randomness, which some scientists feel could open the door to free will. Since quantum physics lies at the heart of reality, it would seem that randomness wins the day.

But some scientists have argued that quantum randomness isn’t truly random. If I roll a die the outcome seems random, but it isn’t really. All of its bumps and turns are caused by the forces of gravity and the table in a complex dance, but that dance is deterministic. The moment the die leaves my hand, its fate is sealed, even though I don’t know the outcome until it happens. Perhaps quantum objects behave in the same way. They seem to act in random ways, but they are really governed by some deterministic hidden variables.

It is a question that has fascinated me since graduate school. My dissertation focused on aspects of quantum gravity, a subject that we still don’t fully understand. One of the reasons for this is that we don’t know how Einstein’s deterministic theory of gravity can fit together with the randomness of quantum mechanics. The question fascinated Einstein as well, and being much smarter than me, he came up with an experiment that could test the idea. Together with Boris Podolsky and Nathan Rosen he presented a thought experiment now known as the Einstein-Podolsky-Rosen experiment, or EPR experiment for short.

To understand the experiment, suppose we have a mischievous mutual friend named Jane. Whenever Jane wears out a pair of running shoes, she loves to prank us by sending one shoe to each of us. So, whenever you get a shoe in the mail from Jane, you know I’ve gotten one too. One of us gets the right shoe, the other the left. But until either of us open our respective box, neither of us know which shoe we have. Once the box arrives at your door, you open it up, and find you have the left shoe. At that moment, you know I must have the right shoe.

This is the basic idea of the EPR experiment. It’s nothing more than a silly prank in our everyday world, but for quantum objects it gets really strange. You may have heard of Schrödinger’s cat, where a quantum cat is neither alive nor dead until observed in a definite state. Like classical cats, quantum cats like quantum boxes. In the quantum realm things can be in an indefinite state until you observe them. It would be as if our boxes contained a pair of something (gloves, shoes, salt and pepper shakers, etc.) but it is impossible to know what specific something until one of us opens their box. Even stranger, how we measure quantum objects determines what the outcome can be. It would be as if opening the box on the side forces it to be a glove, while opening it from the top forces it to be a shoe. How I open my box affects your box miles away. In quantum theory, we say that our two boxes are entangled, so that observing the content of one box also tells us something about the other.

We can’t do this experiment for gloves and shoes, but we can do it with light. Two entangled photons can be sent in opposite directions. I measure the orientation of one photon at random, you measure the other, and then we compare our results. There are lots of different orientations we would measure, so we can each choose the orientation we want. When this experiment is done in the lab, it actually works. And if our measurements are random, there is no way for the photons to know ahead of time which orientation will be measured. So, there can’t be any hidden variable to determine the outcome. Whether we get the left or right shoe, or the left or right glove, the result is truly random.

This is the heart of why Einstein referred to entanglement as “spooky action at a distance.” It’s spooky because entangled objects have a quantum connection, even if they are light-years apart. So, a measurement on one object is a measurement on both through this spooky entanglement. But it’s only spooky if the measurement we make is random. If it’s not random, then no spooky connection is necessary to explain the EPR results.

This is known as the “freedom of choice” loophole. EPR experiments are done in a lab, and even though the choice of how to measure the photons seems random, if there’s no free will then the observation we make was determined by earlier conditions. Since it takes time to set up the experiment in a lab, it’s possible that there are small interactions that could let the quantum system know ahead of time what measurement will be done. Maybe the experiment, the scientists and the lab are all entangled in such a way that the outcome isn’t truly random, so the quantum objects can game the outcome.

To get around the loophole, you have to deal with the speed of light. It’s often said that nothing can travel faster than the speed of light, but it’s really information that can’t travel faster than light. We can send each other telegrams or text messages, but never faster than the time it takes for light to travel between us. In a small lab, light has plenty of time to travel back and forth across the room while the experiment is being set up, so perhaps small bits of information bias the “random” aspect of experiment before it’s even done. That doesn’t seem very likely, but a new experiment has overcome this problem. Rather than using a random number generator in the lab to decide which photon measurement to make, the experimenters used quasars.

Quasars are brilliant beacons of light powered by supermassive black holes in the centers of distant galaxies. The team used random fluctuations in the light from quasars to determine how the photons were measured. Since the light from a quasar has to travel for billions of years to reach us, the fluctuations in brightness happened billions of years before the experiment was done—billions of years before humans even walked the Earth. So, there is absolutely no way for it to be entangled with the experiment.

The result was just what quantum theory predicts. Thus, it looks like there really are no deterministic hidden variables, and randomness is still possible throughout the cosmos.

Of course, randomness isn’t the only thing necessary for free will. But it does mean that your fate is not necessarily sealed. So, when you resist that second cookie, or turn off the TV in the evening, you can take pride in the fact that maybe, just maybe, the choice was yours after all.

====== 15 ========

FALLING WALLS: SOCIAL RELATIONSHIPS AS A SPATIAL PROBLEM

One day, in the deep sea, I went into the blue. Scuba divers are supposed to stay together and follow the reef, but I had drifted away. Above, below and all around was a soft blue haze. The pressure gauge needle pointed outside the safe range but also indicated enough air which was surprising yet also somehow made sense.

I later learned that my scuba-diving buddy pulled me up as I was sinking fast and that hallucinations, such as me thinking my pressure gauge had gone up to 11 quickly arise under sensory deprivation.

Several years later, diving into social neuroscience, it seemed to me that the phenomenon of loneliness was similar to that experience of going into the blue. Beyond the emptiness, it was the lack of social others as reference points in our mental space. We often talk about other people as locations: “He and I got closer”; “They have drifted apart over the years”; “I have a tight social circle”; “She sure is climbing up the social ladder”; and so on. It is almost impossible to describe social relationships without borrowing a spatial metaphor.

Is this a language habit or something deeper about the way our brain handles social life?

We can think of social relationships as a navigation problem: Imagine arriving to a new town. You need to get acquainted with the townspeople in order to find a job and a place to stay. One person approaches you; she is friendly and likes to hang. Another you encounter is a top developer; he is domineering and vain. His assistant is on the admiring side, willing to do anything for you as well.

How would you act? We can envision a game board framed by power and affiliation, where every interaction moves these characters around. Within this space, the trajectories of our relationships evolve. Their paths tell the stories of friendships and foes. Does the brain keep track of social dynamics just as it tracks us moving here and about?

To answer that, we should consider how the brain navigates real, physical space. Studies of spatial navigation typically record the activity of neurons firing when an animal explores the environment. This approach reveals location-specific neurons in a brain region called the hippocampus: a single neuron fires when the animal visits a certain place, and a different neuron fires when it visits the next. The sheer beauty of superimposing neural firing on geographical maps shows how the outside world maps onto our neural landscape.

To examine whether a similar social landscape exists in the brain, my lab used a social interaction game. Participants chose their own adventure by going through a story line; they met different characters and decided how to interact with them. Their choices shaped relationships along the dimensions of power and affiliation. Choosing to abide by one character’s demands, for example, elevated her in power. Engaging another in personal conversation enhanced the affiliation between that character and the participant.

By translating the choices into coordinates on a two-dimensional social space, we could ask whether the brain encoded the characters’ location as the story progressed. Consider an imaginary line drawn between yourself and every character you interact with in this space. The orientation and length of that line, or vector, will signify the whereabouts of each character in your social space. Scanning participants’ brains using functional magnetic resonance imaging as they played the social game enabled us to search for neural signals that corresponded to the characters’ trajectories as the relationships in the story evolved.

We found that the hippocampus tracked that vector’s orientation and that the posterior cingulate cortex tracked its length. These two brain regions, members of a network that supports the mapping of movement in physical space, also track trajectories of the social kind—abstract trajectories that lack any physical reality but are structured and organized alike. Other labs have veered into spaces of odors, sounds and all manner of arbitrary domains. Organizing information along continuous dimensions and tracking the relationships between them constitute a cognitive map. This concept was formulated by American psychologist Edward Tolman in 1948 and is now matched with a neural code.

With multiplex spaces utilizing navigational computations, we can no longer think of the hippocampal formation as the brain’s earthly GPS. The navigation system of the brain organizes information in a relational manner in various realms, from physical arenas to fully abstract terrains. As we progressively build a detailed, mechanistic understanding of how navigational computations are implemented in single neurons and brain networks, we approach the ultimate question: How does the brain integrate maps with multiple dimensions and various domains into one coherent life space?

Editor's note: This post was produced in partnership with the annual Falling Walls Conference in Berlin, which coincides with the anniversary of the fall of the Berlin Wall and showcases the work of researchers from around the world, including the author of this essay.

====== 16 ========

FALLING WALLS: NEW MATERIALS FOR A NEW AGE

To most of us, the word “civilization” is synonymous with enlightenment, culture or refinement; it conjures up images of grand public buildings or brings to mind advanced social systems. But to my mind, civilization is nothing more than a measure of the state of progress in materials science, because from the Stone Age through the Bronze to the Iron Age, every major advance in human civilization has been driven by a fundamental development in materials. The association is so strong that we even name our historical eras after the materials that dominated at the time.

In today’s “Silicon Age,” silicon transistors form the core of much of the microelectronics that enable our modern way of life. And over the past few decades, we have improved the properties of silicon devices to an astonishing extent, enabling the transformation of clunky old desktop computers into sleek smartphones while taking for granted the exponential increase in capability—and corresponding decrease in size and cost—as captured by Moore’s Law.

But this silicon revolution will soon be forced to come to an end as we start to run into fundamental physical limits set by the size of the individual atoms that make up the silicon material. And this means that the steady march toward faster, smaller, lighter products with more and more functionality can’t continue within our existing framework.

Although it might seem that our electronic devices are already light and small and powerful enough, this roadblock is in fact a profound problem for society. Worldwide use of microelectronics is expanding so rapidly that, by many projections, more than half of the world’s energy will be consumed by information technologies within a couple of decades. And this consumption is not sustainable. To maintain and improve our global standard of living, we need to step beyond the Silicon Age, and to do this we need a new material.

Twenty years ago, I was a young postdoctoral researcher working on ferromagnetic materials—these are materials that contain magnetic dipoles with their north and south poles lined up in the same direction—in a research group that specialized in ferroelectric materials, which are materials with aligned electric dipoles made of positive and negative charges. My plan was to take the techniques that my host group had developed to study ferroelectric materials and apply them to the study of ferromagnets; the “ferro” in both names reflects similarities in the underlying physics between the two material classes.

I noticed, though, that the kinds of materials I was working on were different from those of my colleagues. For example, most ferromagnetic materials are black metals, like iron, whereas most ferroelectric materials are transparent ceramics. The question “Why are there so few magnetic ferroelectrics?” intrigued me to the extent that finding its answer became the focal point of my research program.

What I discovered was very simple: the atoms that form the kinds of chemical bonds needed to produce magnetic dipoles in a material have different chemistries from those that tend to make electric dipoles. But there is no fundamental reason why the two phenomena can’t be combined. And armed with this understanding, my collaborators and I were able to develop a new class of materials called multiferroics, which indeed are magnetic and ferroelectric.

So why are multiferroics important? Well, magnetic materials are complementary to silicon in today’s technologies—where silicon is used for processing information, magnetic materials are used for storing it, by representing the 1s and 0s of digital electronics through opposite orientations of their magnetic dipoles. And magnetic materials are very good at this, because these magnetic data bits are stable, small and can be accessed quickly. Yet magnetic devices come with a cost—producing the magnetic fields that are needed to control the magnetism requires bulky components and uses a lot of energy.

But imagine the possibilities offered by a material that is both magnetic and ferroelectric. Multiferroic materials still have all of the advantages of magnetic materials, but in addition their magnetism can be controlled using electric fields. And compared with magnetic fields, electric fields are efficient: they can be made of tiny components, and they use vanishingly small amounts of energy. Our new multiferroic materials are poised to enable entirely new device paradigms, different ways of designing technologies along lines we are only just starting to imagine.

What are the walls that we need to break down so we can enter a new “Multiferroics Age”? We need to develop new materials in which the magnetic and electric dipoles remain stable at room temperature, even when we make them very small. We need to understand the process of reorienting the dipoles well enough to do it with very small electric fields. And we need to make sure that our new materials are abundant on the earth, environmentally benign, and cheap and easy to process. And in return, our multiferroics are providing us with a playground for exploring a host of exciting fundamental scientific questions, as well as maybe, just maybe, paving the way to the next materials age.

Editor's note: This post was produced in partnership with the annual Falling Walls Conference in Berlin, which coincides with the anniversary of the fall of the Berlin Wall and showcases the work of researchers from around the world, including the author of this essay.

====== 17 ========

FALLING WALLS: THE PAST, PRESENT AND FUTURE OF ARTIFICIAL INTELLIGENCE

Editor’s Note: The Falling Walls Conference is an annual, global gathering of forward thinking individuals from 80 countries organized by the Falling Walls Foundation. Each year, on November 9—the anniversary of the fall of the Berlin Wall—20 of the world’s leading scientists are invited to Berlin to present their current breakthrough research. The aim of the conference is to address two questions: Which will be the next walls to fall? And how will that change our lives? The author of the following essay is speaking at this year’s Falling Walls gathering.

As a boy, I wanted to maximize my impact on the world, so I decided I would build a self-improving AI that could learn to become much smarter than I am. That would allow me to retire and let AIs solve all of the problems that I could not solve myself—and also colonize the universe in a way infeasible for humans, expanding the realm of intelligence.

So I studied mathematics and computers. My very ambitious 1987 diploma thesis described the first concrete research on meta-learning programs, which not only learn to solve a few problems but also learn to improve their own learning algorithms, restricted only by the limits of computability, to achieve super-intelligence through recursive self-improvement.

I am still working on this, but now many more people are interested. Why? Because the methods we’ve created on the way to this goal are now permeating the modern world—available to half of humankind, used billions of times per day.

As of August 2017, the five most valuable public companies in existence are Apple, Google, Microsoft, Facebook and Amazon. All of them are heavily using the deep-learning neural networks developed in my labs in Germany and Switzerland since the early 1990s—in particular, the Long Short-Term Memory network, or LSTM, described in several papers with my colleagues Sepp Hochreiter, Felix Gers, Alex Graves and other brilliant students and postdocs funded by European taxpayers.In the beginning, such an LSTM is stupid. It knows nothing. But it can learn through experience. It is a bit inspired by the human cortex, each of whose more than 15 billion neurons are connected to 10,000 other neurons on average. Input neurons feed the rest with data (sound, vision, pain). Output neurons trigger muscles. Thinking neurons are hidden in between. All learn by changing the connection strengths defining how strongly neurons influence each other.

Things are similar for our LSTM, an artificial recurrent neural network (RNN), which outperforms previous methods in numerous applications. LSTM learns to control robots, analyze images, summarize documents, recognize videos and handwriting, run chat bots, predict diseases and click rates and stock markets, compose music, and much more. LSTM has become a basis of much of what's now called deep learning, especially for sequential data (note that most real-world data is sequential).

In 2015, LSTM greatly improved Google's speech recognition, now on over two billion Android phones. LSTM is also at the core of the new, much better Google Translate service used since 2016. LSTM is also in Apple's QuickType and Siri on almost 1 billion iPhones. LSTM also creates the spoken answers of Amazon’s Alexa.

As of 2016, almost 30 percent of the awesome computational power for inference in all those Google data centers was used for LSTM. As of 2017, Facebook is using LSTM for a whopping 4.5 billion translations each day—more than 50,000 per second. You are probably using LSTM all the time. But other deep learning algorithms of ours are also now available to billions of users.

We called our RNN-based approaches “general deep learning," to contrast them with traditional deep learning in the multilayer feed-forward neural networks (FNNs) pioneered by Ivakhnenko & Lapa (1965) more than half a century ago in the Ukraine (which back then was part of the USSR). Unlike FNNs, RNNs such as LSTM have general purpose, parallel-sequential computational architectures. RNNs are to the more limited FNNs as general-purpose computers are to mere calculators.

By the early 1990s, our (initially unsupervised) deep RNNs could learn to solve many previously unlearnable tasks. But this was just the beginning. Every five years computers are getting roughly 10 times faster per dollar. This trend is older than Moore's Law; it has held since Konrad Zuse built the first working program-controlled computer over the period 1935–1941, which could perform roughly one elementary operation per second. Today, 75 years later, computing is about a million billion times cheaper. LSTM has greatly profited from this acceleration.

Today's largest LSTMs have a billion connections or so. Extrapolating this trend, in 25 years we should have rather cheap, human-cortex-sized LSTMs with more than 100,000 billion electronic connections, which are much faster than biological connections. A few decades later, we may have cheap computers with the raw computational power of all of the planet’s 10 billion human brains together, which collectively probably cannot execute more than 1030 meaningful elementary operations per second. And Bremermann’s physical limit (1982) for 1 kilogram of computational substrate is still over 1020 times bigger than that. The trend above won't approach this limit before the next century, which is still "soon" though—a century is just 1 percent of the 10,000 years human civilization has existed.

LSTM by itself, however, is a supervised method and therefore not sufficient for a true AI that learns without a teacher to solve all kinds of problems in initially unknown environments. That's why for three decades I have been publishing on more general AIs.

A particular focus of mine since 1990 has been on unsupervised AIs that exhibit what I have called "artificial curiosity" and creativity. They invent their own goals and experiments to figure out how the world works, and what can be done in it. Such AIs may use LSTM as a submodule that learns to predict consequences of actions. They do not slavishly imitate human teachers, but derive rewards from continually creating and solving their own, new, previously unsolvable problems, a bit like playing kids, to become more and more general problem solvers in the process (buzzword: PowerPlay, 2011). We have already built simple "artificial scientists" based on this.

Extrapolating from this work, I think that within not so many years we'll have an AI that incrementally learns to become as smart as a little animal—curiously and creatively and continually learning to plan and reason and decompose a wide variety of problems into quickly solvable (or already solved) sub-problems. Soon after we develop monkey-level AI we may have human-level AI, with truly limitless applications.

And it won't stop there. Many curious AIs that invent their own goals will quickly improve themselves, restricted only by the fundamental limits of computability and physics. What will they do? Space is hostile to humans but friendly to appropriately designed robots, and offers many more resources than our thin film of biosphere, which receives less than a billionth of the sun's light. While some AIs will remain fascinated with life, at least as long as they don't fully understand it, most will be more interested in the incredible new opportunities for robots and software life out there in space. Through innumerable self-replicating robot factories in the asteroid belt and beyond they will transform the solar system and then within a few hundred thousand years the entire galaxy and within billions of years the rest of the reachable universe, held back only by the light-speed limit. (AIs or parts thereof are likely to travel by radio from transmitters to receivers—although putting these in place will take considerable time.)

This will be very different from the scenarios described in the science fiction novels of the 20th century, which also featured galactic empires and smart AIs. Most of the novels’ plots were very human-centric and thus unrealistic. For example, to make large distances in the galaxy compatible with short human life spans, sci-fi authors invented physically impossible technologies such as warp drives. The expanding AI sphere, however, won't have any problems with physics' speed limit. Since the universe will continue to exist for many times its current 13.8-billion year age, there will probably be enough time to reach all of it.

Many sci-fi novels featured single AIs dominating everything. It is more realistic to expect an incredibly diverse variety of AIs trying to optimize all kinds of partially conflicting (and quickly evolving) utility functions, many of them generated automatically (my lab had already evolved utility functions in the millennium that just ended), where each AI is continually trying to survive and adapt to rapidly changing niches in AI ecologies driven by intense competition and collaboration that lie beyond our current imagination.

Some humans may hope to become immortal parts of these ecologies through brain scans and "mind uploads" into virtual realities or robots, a physically plausible idea discussed in fiction since the 1960s. However, to compete in rapidly evolving AI ecologies, uploaded human minds will eventually have to change beyond recognition, becoming something very different in the process.

So humans won't play a significant role in the spreading of intelligence across the cosmos. But that's OK. Don’t think of humans as the crown of creation. Instead view human civilization as part of a much grander scheme, an important step (but not the last one) on the path of the universe towards higher complexity. Now it seems ready to take its next step, a step comparable to the invention of life itself over 3.5 billion years ago.

This is more than just another industrial revolution. This is something new that transcends humankind and even biology. It is a privilege to witness its beginnings, and contribute something to it.

The Falling Walls Conference is supported by the German Federal Ministry of Education and Research, the Helmholtz Association, the Robert Bosch Stiftung and the Berlin Senate. It receives support and advice from a wide variety of international top-class universities and research institutions as well as foundations, corporations, noted individuals and non-governmental organizations.

====== 18 ========

FALLING WALLS: HOW REPAIRING THE OZONE HOLE HELPED THE CLIMATE

In September 1987, in response to evidence that the chemicals known as chlorofluorocarbons (CFCs) were damaging the atmosphere’s ozone layer, the countries of the world drafted a landmark agreement known as the Montreal Protocol, which limited the use of those chemicals. Since then, the protocol has been successful not only at protecting the ozone layer, but, since CFCs are also heat-trapping greenhouse gases, at helping limit the risk of climate change as well. In fact, the signatories amended the protocol last year to focus entirely on climate protection.

The story began in 1974, with the discovery by Mario Molina and Sherwood Rowland that CFCs, which were being used in increasing quantities as refrigerants (in refrigerators, freezers and air conditioners), in aerosol spray cans, as industrial solvents, and as blowing agents plastic foam and other products, could deplete the ozone layer by catalytic chemical reactions. CFCs are stable, man-made chemicals that are only broken down when they reach the stratosphere, between 15 and 50 kilometers above Earth’s surface. The chlorine atoms liberated in that process would, Molina and Rowland argued, initiate a series of chemical reactions resulting in the destruction of ozone. This was important because the so-called ozone layer in the stratosphere absorbs harmful solar ultraviolet radiation, thereby protecting living things on earth. An increase in UV radiation can, among other things, cause both skin cancers and cataracts.

This danger was largely theoretical at first, but in 1985, Joe Farman and his colleagues with the British Antarctic Survey discovered that ozone over the Antarctic continent was dropping by about a third every austral spring. They linked this to the increase in chlorine in the stratosphere. In 1995, Molina and Rowland, along with Paul Crutzen, shared the Nobel Prize in Chemistry for their groundbreaking work.

Alarmed by these discoveries, the countries of the world rapidly agreed to limit the use of CFCs under the Montreal Protocol, which was put in place just two years later. Successive amendments have strengthened and broadened the protocol. The result is that the use of CFCs is now phased out globally and emissions have decreased by 90 percent or more from their peak values. Measurements show that the atmospheric abundance of CFCs is also decreasing. Due to the 50- to 100-year atmospheric residence time of most CFCs, the ozone layer has responded slowly. But observations from satellites and ground based stations show that it has begun to recover. Without the Montreal protocol, CFCs would have continued to increase, and scientist have estimated that by 2100 the annual number of skin cancer cases would have quadrupled (Slaper et al. 1996).

In 2007, my U.S. colleagues and I (Velders et al., 2007) showed that the Montreal Protocol was not only important for the ozone layer, but also contributed to climate protection. CFCs are potent greenhouse gases; per kilogram emission the major CFCs are 5,000 to 11,000 times more powerful at climate forcing than the main greenhouse gas CO2. In fact, by 2010, the Montreal Protocol had achieved five to six times larger climate benefits than the Kyoto Protocol, which was designed for climate protection.

The story is not over, however. The Montreal Protocol banned CFCs and other chemicals, but we still have refrigerators and air conditioners. This was possible because we were able to substitute other gases, especially hydrofluorocarbons (HFCs), in their place. As a result, the use of HFCs has grown significantly over the past two decade. HFCs do not affect the ozone layer; unfortunately, they, too, are potent greenhouse gases. Projections I made with colleagues in 2009 and 2015 (Velders et al., 2009, 2012, 2015) showed that if this growth continues, their contribution to climate change will significantly offset the climate benefits of the Montreal Protocol.

Based on the scientific evidence, rooted in observations, theory and modeling studies, the politicians decided to act again. They agreed to use the Montreal Protocol, designed to protect the ozone layer, to fight climate change. In October 2016 in Kigali, Rwanda, they agreed to amend the protocol to strongly limit the future use of HFCs globally. Between 2036 and 2046 the use of HFCs must now be reduced by 85 percent compared to an agreed baseline. In the final hours of the meeting in Kigali, I calculated that with this agreement, the contribution from HFCs to the global average surface warming would be limited to less than 0.1 degree Celsius by 2100, compared with 0.3 to 0.5 degree C without the agreement. This is a significant step towards the goals of the Paris climate accord of December 2015: to keep global temperatures below 2 degrees C by the end of the century, relative to pre-industrial times. I hope that a sufficient number of countries will have ratified the Kigali Amendment for it to enter into force on the agreed-upon date of January 1, 2019.

The Montreal Protocol is widely considered to be the most successful international environmental agreement. In my view, the success, for both ozone and climate protection is the result of sound scientific research, clear communication, fruitful interactions between scientists, policymakers, industry, and environmental groups, and the willingness of all these parties to reach an agreement, while respecting each other’s position. A great example to follow.

The Falling Walls Conference is supported by the German Federal Ministry of Education and Research, the Helmholtz Association, the Robert Bosch Stiftung and the Berlin Senate. It receives support and advice from a wide variety of international top-class universities and research institutions as well as foundations

References:

====== 19 ========

HOW AND WHY SCIENTISTS REDEFINED THE KILOGRAM

Last Friday brought big news to the world of physics: at a meeting in France, scientists from 57 countries voted to replace the famous object known as Le Grand K with a new system of defining the kilogram. This change was a long time coming, and as the physics community has prepared for it over the years, Scientific American has been there to cover the topic. The following graphic from the archives shows how scientists went about redefining the kilogram.

Credit: Jen Christiansen

And the graphic below, from 2017, below puts the redefinition in context of a larger planned overhaul of the International System of Units.

====== 20 ========

TRANSFORMING ROBOT CHANGES SHAPE AT WILL

Researchers have created a 'modular' robot which can analyze its environment and reconfigure itself to overcome obstacles and achieve tasks.

This video was reproduced with permission and was first published on October 31, 2018. It is a Nature Video production.

====== 21 ========

TO STAVE OFF WINTER'S CHILL, HONEYBEES HUG

When staying warm is a matter of survival, they use this tried-and-true strategy.

====== 22 ========

HOW DO BIRDS KNOW TO FLY SOUTH?

Birds such as the Arctic tern used magnetic particles and eye pigments to navigate.

====== 23 ========

A NOBEL LAUREATE EXPLAINS AMERICA'S RIGGED ECONOMY

The United States has the highest level of economic inequality of any developed country. Professor Joseph E. Stiglitz, winner of the 2001 Nobel Prize in Economics, explains why he thinks the American economy is rigged, and what that means for future generation.

To learn more about America's rigged economy and what we can do to fix it, click here.

====== 24 ========

HAWK MOTHS HOLD STEADY WHEN FACED WITH TURBULENCE

Hawk moths hover while they feed, but they recover surprisingly quickly when knocked off-balance. Scientists use high-speed video and mini-cannons made of plastic toy parts to understand how hawk moths respond to disturbances midair.

"Lens of Time: The Art of Staying Stable" was first published on bioGraphic © 2018 California Academy of Science.

====== 25 ========

THE CRUSADE AGAINST DANGEROUS FOOD PART 2

Hi, Steve Mirsky here. Welcome back for part 2 of my conversation with Deborah Blum, author of the Poison Squad.

BLUM SEGMENT

That’s it for this episode. Get your science news at our website, www.scientificamerican.com. And don’t forget to also visit our friends at the Nature website, www.nature.com, where you can check out the Nature podcast—the latest one features a nearby exoplanet and a discussion of how social media may be messing up clinical trials. Because people are able to find others in the trial and figure out if they got the drug or the placebo. Maybe we need a placebo Facebook.

And back to SciAm, follow us on Twitter, where you’ll get a tweet whenever a new item hits the website. Our twitter name is @sciam. For Scientific American’s Science Talk, I’m Steve Mirsky, thanks for clicking on us.

====== 26 ========

DO WINE OVER THOSE BRUSSELS SPROUTS

Thanksgiving is, of course, really all about the side dishes. And alongside mashed potatoes and yams, Brussels sprouts are a common side on many Thanksgiving tables. Not that they're equally appreciated. But science is here to save turkey day, with a way to mitigate the sprouts' intense, slightly bitter flavor: take swigs of red wine as you eat 'em.

Like any human research study, or perhaps more importantly for one in which you'll be forcing people to eat Brussels sprouts, the project started off with approval from an ethics committee.

Researchers then served 28 volunteers slices of microwaved Brussels sprouts, and asked them to rate the intensity or bitterness of their flavor on a scale of 1 to 10. They then alternated their bites with red wine, gravy, and bottled water. And rated the flavor again.

Turns out, the subjects scored the sprouts as significantly less intense after a sip of wine: 3.5 out of 10, compared to 5.5. Maybe, the scientists write, because the astringency of wine interferes with saliva's ability to deliver bitter flavor molecules to the tastebuds.

The results are in the Journal of Texture Studies…a real publication. [Guy Carpenter et al, Wine astringency reduces flavour intensity of Brussels Sprouts]

Unfortunately for the kids at the table, gravy and water did not do the taste trick. But for adults who choose to use this Thanksgiving hack—please imbibe responsibly. Though I don't imagine you'll be eating that many Brussels sprouts.

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 27 ========

THE CRUSADE AGAINST DANGEROUS FOOD PART 1

Welcome to Scientific American’s Science Talk, posted on November 21, 2018. I’m Steve Mirsky. On this episode:

BLUM CLIP

That’s Deborah Blum. At the Sacramento Bee newspaper she won the 1992 Pulitzer Prize for beat reporting. After almost two decades as a professor in the School of Journalism and Mass Communication at the University of Wisconsin–Madison, she became the director of the Knight Science Journalism Program at MIT in 2015. And her latest book is The Poison Squad: One Chemist’s Single-Minded Crusade for Food Safety at the Turn of the Twentieth Century. We spoke in October when we were both in Washington DC for a conference. You can listen while you throw out your Romaine lettuce or cook your turkey to make sure you kill any salmonella. Here’s part 1.

BLUM SEGMENT

Deborah Blum’s book is called the Poison Squad. Tune back in for part 2 to hear about…the Poison Squad. We haven't even gotten to that yet.

====== 28 ========

RAINS BRING A MICROBIAL MASSACRE TO CHILEAN DESERT

The Atacama desert in Chile is one of the driest spots on Earth. Sometimes, you can't see any life at all.

"As I was a kid those drives were very boring…because there was nothing to see."

Armando Azua-Bustos was born and raised in Atacama. He’s now an astrobiologist at the Spanish National Research Council's (CSIC) Center for Astrobiology.

But he says, with closer inspection, life can be found. "There is life around, but you have to take a microscope to see microorganisms in those driest places in the Atacama."

Then in 2015, and again in 2017, freak storms from the Pacific flooded the Atacama. Ten times the usual amount of rain fell, turning some of the driest parts of the desert into lagoons.

But the desert's hardy microbial life didn't exactly burst into bloom. "I start looking at the microscope and I couldn't see anything! That was surprising. I was expecting to see a zoo of little things moving all around. But I couldn't see anything."

In fact, after sampling three of the newly submerged areas, his team found only a quarter of the microscopic species they'd previously isolated in the desert region—perhaps, he says, because the water killed the rest, through a process called "osmotic shock." "The cell doesn't have the mechanisms to get all the water that is going into the cell to get it out, so they start inflating like a small balloon until they burst out."

The results are in the journal Scientific Reports. [A. Azua-Bustos et al., Unprecedented rains decimate surface microbial communities in the hyperarid core of the Atacama Desert]

The microbial massacre should serve as a cautionary tale, he says, as we search for similar dry-adapted lifeforms on Mars. Because several of the life-detecting experiments performed by the Viking landers involved—you guessed it—adding water. And it would be tragic if we killed the first extraterrestrial life we found.

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 29 ========

CONSENSUAL HUGS SEEM TO REDUCE STRESS

When a friend comes to you after a stressful day, how do you comfort them? Do you let them rant? Do you pour them a glass of wine? Those could work. But a new study finds that a very effective technique is also simple and easy.

“Hugging.”

Michael Murphy is a psychology postdoc at Carnegie Mellon University in Pittsburgh. He wanted to know if people who received hugs regularly could handle stress and conflict better.

“Individuals who report perceiving the availability of a network of supportive individuals tend to show better adaptation when faced with stress.”

But just because you have a support network does not mean that you definitely feel that support.

“So some researchers have argued that many of the behaviors we use to support others who are stressed might actually be counterproductive because these behaviors might unintentionally communicate to others that they're not competent to manage stress.”

Murphy and his team interviewed 404 men and women every evening for two weeks.

“During these interviews, the participants were asked a simple yes or no question—whether somebody had hugged them that day—and a simple yes or no question of whether they had experienced conflict or tension with somebody that day. They also were asked questions about their social interactions—how many social interactions they had that day—and responded to questions about negative and positive mood states.”

And the researchers found that individuals who experienced a conflict were not as negatively affected if they received a hug that day as were participants who experienced conflict and didn’t get a hug. Murphy and his team also saw that people who received a hug didn’t carry the negative effect to the next day, while those who did not receive a hug would. The findings are in the journal PLOS ONE. [Michael L. M. Murphy, Denise Janicki-Deverts and Sheldon Cohen, Receiving a hug is associated with the attenuation of negative mood that occurs on days with interpersonal conflict]

Murphy does include this caveat: “So our findings should not be taken as evidence that people should just start hugging anyone and everyone who seems distressed. A hug from one boss at work or a stranger on the street—that could be viewed as neither consensual or positive.”

The idea is to relieve stress. Not add to it.

—Lucy Huang

[The above text is a transcript of this podcast.]

====== 30 ========

A THANKSGIVING MEDITATION IN THE FACE OF A CHANGING CLIMATE

The Universe is not perfect, and that’s why you exist. There were tiny wrinkles at the beginning of space and time, and these led to tiny imperfections in the smooth face of the early Universe. In some regions, there was a bit more matter, in others a bit less. This slight difference multiplied as the gravity of the rich regions pulled in the matter from the poorer regions. As in real life, the rich got richer. But this is why the cosmos is dotted with stars and galaxies. Every single speck of light you’ve ever seen in the nighttime sky is evidence of the Universe’s flaws.

In one small gravity well, dust and gas collapsed and piled on top itself to create a ball, and then a larger ball, and eventually a star. This is our star, and there is nothing special about it. But its ordinariness is the fuel for all the life we’ve ever known. In the sun’s hot center, protons are flung around so violently by the heat that they overcome their natural electrical repulsion. When they come together, they make something less than the sum of their parts. The difference is translated into energy, some of which comes to you. You are fortunate to benefit from an enormous nuclear reactor in the sky. If the sun were made of coal, it would have burned out sixty-five thousand years after it formed. Everything you’ve ever eaten or drunk, every move you’ve ever made, every beautiful thing you’ve ever seen is because of a mediocre star in an unexceptional galaxy.

You live on a small rock not too close and not too far from the Sun. You go around it once per year in an almost perfect circle, the year marked in seasons caused by axial tilt. Your planet can and does wobble in its orbit over tens or hundreds of thousands of years, with the circle becoming an ellipse, the tilt becoming larger or smaller, and the North Star alternating between Polaris and Vega. Any small shift in the orbital parameters can lead to massive climatic shifts, blanketing the planet in glaciers. You are lucky to live in an interglacial, a respite from the Ice Age that has lasted longer than human civilization, and may outlast us, too.

On this planet, everything is unequal but intertwined. In the tropics, hot air moves skyward, shedding water on the rainforests below as it rises and cools. The air flows toward the colder poles like a flock of birds returning home for the summer. Eventually, it cools and begins to sink, pushing away the air underneath. The sinking air is dry and cloudless, and underneath are the Sahara, the Empty Quarter, and the Kalahari. The deserts are a gift from the tropics. But the deserts give, too. Dust kicked up from the Sahara is carried by air currents across the globe, where it fertilizes the lush forests of the Amazon.

The air you breathe contains oxygen put there by land plants and phytoplankton, which use the carbon dioxide you exhale to turn light into sugar. There is enough land to live and farm on, and enough ocean to provide food and transportation and mystery. Millions of years of evolution has produced a staggering array of animals and plants, and all of your friends and family, too.

Dig deep into the land, and the layers of rocks reveal a history punctuated by mass death. There have been five mass extinctions. You are living through the sixth. You helped cause it, which means you have the power to stop it. You are not an asteroid or a volcano.

The civilization you live in that creates the books you read, the movies you enjoy, the technology that allows you to stay in touch with distant family and friends- this has developed during the Holocene, a period of remarkably stable climate. Arguably, we don’t know how to think about climate change because we’ve never really had to think about climate. It’s always been a hum in the background, small variations around a mean that we take for granted. Now, that background note is growing louder and higher.

Our climate is changing because of our actions. We can already see the impacts: changes in the range and behavior of animal species, coastal cities smashed by hurricanes and inundated by floodwaters, a haze of unseasonal wildfire smoke. Science says nothing about how to feel about these changes. I feel grief, guilt, anger, determination, hope, and sadness all at the same time. But what I feel more than anything is gratitude for what we have. We live on a medium-sized rock that goes around a garden-variety star in a galaxy that exists only because of a flaw in the smooth perfection of the early cosmos.

Science says there is nothing special about our place in the Universe. I have to disagree.

====== 31 ========

YOU CAN'T SAY "HAPPY THANKSGIVING" IN DOTHRAKI

I celebrated Thanksgiving for the first time after I moved from Spain to the US as a young adult, and quickly embraced the concept of a holiday centred on gratitude. Even though I didn’t grow up with the tradition, I told myself the act of giving thanks is universal.

I was wrong.

If you watch Game of Thrones, you may recall that Dothraki speakers are unusual in that they have no word for ‘thank you.’ It turns out, many languages around the world also lack a way to say ‘thanks,’ according to a study published earlier this year in Royal Society Open Science.

I reached out to David J. Peterson, who created the Dothraki language for the HBO show, to get his take on this study—and what it might reveal about Dothraki culture.

The interview below is edited for clarity and conciseness.

Illusion Chasers: A recent study about gratitude expression has found that many human languages have no word for thanks. Were you surprised when you learned about this?

Peterson: Absolutely. Yes. Very surprising. The way this all started, I created the Dothraki language when they were going to film the pilot of Game of Thrones, and this was going to be an internal pilot that was just showed to HBO, and then HBO would decide if they were going to turn this show into a series or not. I had produced over 300 pages of material to show to the producers to help to distinguish my proposal from everybody else's. I [also] made a one-page sheet of fun facts about the language. I mentioned what the longest word of Dothraki was, and I also mentioned that Dothraki had three words for push, three words for pull, three words for carry, and fourteen words for horse, but it didn't have a word for please. So at the time, Dothraki did have a word for thank you because it just seemed like it should, and so I created one. After they chose [my proposal], they revised the pilot script. And of their own accord, without consulting me, they added the line about Dothraki not having a word for thank you. This came from my idea that Dothraki didn't have a word for please [but] I never said anything about thank you. And in fact, Dothraki did have one [word for thank you].

Illusion Chasers: What did you think of the decision to not have a way to say ‘thanks’ in Dothraki?

Peterson: I was always kind of unhappy with the situation. I thought it was unrealistic that a language wouldn't have a word for thank you.

Illusion Chasers: But now researchers say that it is realistic not having a word for ‘thanks.’

Peterson: Yeah. When I read the study and looked at it, it kind of hit me, and I was struck, and it made absolute sense. I think my instinct was right that there would be no culture where you couldn't or wouldn't express gratitude. But where I was wrong, where I was using my English brain, is thinking that you had to have a word to express gratitude and then, furthermore, that you would express gratitude in all of the same places from culture to culture.

Illusion Chasers: According to this study, we express our gratitude more reliably to strangers than to our family and friends, because we are implicitly aware of our rights and duties with regards to people close to us. Is it fair to speculate that there is no need to say thanks in Dothraki society because of an implicit understanding of rights and obligations?

Peterson: [Dothraki] society, such as it is, is quite spread out. It's very rule governed, but it's not as if everybody knows everybody. They have one major city where few people live year-round. Different bands that come back to the city, maybe once a year, maybe once every two years, and then branch out in many, many different directions, and then just they're constantly on the move. Certainly amongst their Khalasar, which is the word for their tribe or band, everybody is going to know everybody. But much of their existence is spent interacting with strangers, and not just strangers that don't speak Dothraki, but strangers that are Dothraki that they'll meet from time to time either on their trail or back in their city.

Illusion Chasers: Without a word for thanks, how do the Dothraki express appreciation?

Peterson: In the books, what kind of replaces [thanking somebody] is gifts. When Dothraki respect somebody, whether it's an individual or a society, they will bring them gifts unannounced. They will exchange gifts, not on any preordained day or for any custom that's been settled upon, but it will just be one day the Dothraki arrive and they will give you a gift, and you should give them gifts as well. I don't think this is in the show, it’s just mentioned by George R. R. Martin in the books. What we don't really see is very small interactions between one band of Dothraki on an ordinary day where nobody's riding off or going to war and where there isn't a foreigner present. Basically, any time we see Dothraki culture in the books, it's through the eyes of a foreigner, and so there's always that layer between us and their society. In my opinion, there is some form of reciprocity that doesn't seem to be based on gratitude, but it's more based on respect and the estimation of the strength of their friend or adversary.

Illusion Chasers: This same study mentions that people can find it awkward or even rude in some cultures when others thank them. Would the Dothraki feel that way?

Peterson: It would depend on the social structure. If they viewed them as somebody that was not a martial threat, they would find it silly and a sign of weakness. If it was somebody that was far more powerful than they were, I think that they would find it incredibly awkward and wouldn't know how to react to that.

Illusion Chasers: Again based on this study, even though saying thanks is fairly unusual around the globe, what seems to be universal is the willingness to comply with small requests, such as sharing a snack. How do the Dothraki respond to requests for small favors?

Peterson: For the most part, if they need something, they’ll go and take it. If the person they take it from respects them or they're a close friend or a family member, then that's it. And then that's fine. So I would say, they should fall into the universal normal range of allowing and complying with requests.

The only thing that I would add is that, much like, I think, everybody else who reads the books, I really am just kind of a researcher, in terms of Dothraki culture. In creating the language and fleshing it out, I'm not the ultimate authority on everything having to do with the Dothraki. That's certainly George R. R. Martin. So everything I said, take it with that level of authority. It's not absolute. It's based on what I've studied.

====== 32 ========

IMMIGRATION STATUS SHOULD NOT SILENCE SCIENTISTS

Scientists are finding their voices. Researchers once reliant on press officers and journalists to explain their work to the general public can now do so on their own, sometimes by starting a blog or by pitching magazines and websites to pen articles under their own names.

Researchers’ interest has grown in part because universities have encouraged them to write, offering writing courses and workshops for doctorate students and postdocs. Other times, researchers are seeking it out on their own, joining workshops of scientists and journalists like NeuWrite Downtown , which we run. “There's a lot of value in publishing; you can reach audiences you can't necessarily reach in academic institutions,” said Heather McKellar, the senior manager of education and outreach programs at the Neuroscience Institute at New York University. “There are a lot of people who don't have access to scientists, and written and online material can provide that.”

But the opportunity to write for the general public isn’t open to all scientists. For international researchers who are in the U.S. on particular types of visas, doing the wrong kind of work could put them at risk of deportation.

“The public is just really interested in who we are and what we do. And they like to hear directly from scientists,” said Jennifer Raff, a blogger and an assistant professor of anthropology at the University of Kansas. “Since many of us are paid by taxes, we have an obligation to return information to the public, and to be accessible to the public.”

But for about 39,000 PhD students, or just over half the total number of doctoral candidates in the United States, it could prove to be too risky. Most of these foreign-born researchers are in the U.S. on F-1 (for students), J-1 (for work-study), and H-1B (for specialty occupation) visas. The terms for these visas vary slightly, but all prohibit the visa-holder from “unauthorized employment”—that is, doing any work outside the university they’re working for.

Working for anyone other than the university could mean violating the terms of the visa. “Generally speaking, if you engage in any violation of the terms of your visa, you are no longer in lawful immigration status,” said Careen Shannon, a partner at Fragomen, Del Rey, Bernsen & Loewy, LLP, a law firm that focuses on immigration law. “If such a violation were to come to light in the course of seeking an extension of your temporary stay or adjustment of status to permanent residence, recent changes in immigration policy mean that you could quickly be subject to a ‘Notice to Appear’ in immigration court for the purpose of removal proceedings.”

That puts writing for a publication in a strange gray area. Because what exactly constitutes “work” can be subject to debate, immigration lawyers will give people different advice based on the specific facts and circumstances presented, Shannon said. Most lawyers will tell students to talk to the international student office at their university, but these offices can often only offer a blanket statement and sometimes contradict one another, which can leave researchers feeling unsupported and confused. Publishers themselves sometimes aren’t sure; sometimes publications simply don’t know a writer’s visa status, or it doesn’t come up. “We haven't had a situation that I know of where we've hired an international researcher,” Rick Berke, executive editor of the Boston-based biomedical news Stat said via e-mail.

That uncertainty can have a chilling effect on would-be writers. Karen Kwon, a fifth-year chemistry PhD student at Columbia University, had been talking with an editor at the American Chemical Society about writing a short piece for their Graduate and Postdoctoral Chemist magazine . But Kwon is on an F-1 visa. When the editor suggested paying her in gift cards, Kwon was nervous. “Since I might be applying for a green card in the future, I don't want to take a risk by finding a way around,” she said.

There does, however, seem to be a way for visa-holders to still get their voices heard. They can write for general interest publications as “volunteer contributors,” eschewing payment and the stability of a contract (which more or less guarantees its publication) for the simple opportunity of writing. One of the authors of this piece—Huayi Wei, a neuroscience PhD student and an F-1 visa holder—isn't getting paid for her work (the other author, Alexandra Ossola, is a U.S. citizen and did receive a modest payment).

Some publications allow writers to work without a contract, while others may insist on it. If you don’t receive compensation, or if there's a clause addressing this in the contract, it may be possible to argue that what you're doing does not constitute "employment." But since there may be other factors to consider in making that determination, we suggest that you seek individual legal help if you are signing a contract, just to be sure.

Writing for free is, admittedly, not ideal. Writing without a contract could mean that a researcher could do the work but with little assurance it will be published even if it's of high quality. Already-overworked researchers might need a little extra incentive to make time to write. And it doesn’t set a good precedent for full-time freelance journalists; why would an editor pay someone to write about science when someone else even closer to the work itself could do it for free?

“Getting paid to write legitimizes the seriousness of the writing, and it shows that an organization values my time and expertise,” Raff said. She hadn’t heard that international researchers sometimes couldn’t get paid, but when we told her, her first reaction was: “Oh, that sucks. I hope that all scientists, including international scientists, could have the opportunity to develop their writing and voice.”

Granted, the law could change, though it’s not likely to become more relaxed, especially not under an administration that actively worked to reduce the number legal immigrants in the U.S. as well as the resources available to them.

But it’s important for scientists to know that they can, in fact, write for their dream publication. It’s important for publishers to court and cultivate those voices, too. Because life-saving, world-changing scientific breakthroughs don’t happen when information is siloed. Because collaboration is the only way to go far in science, or really in any other field. Because if we want to push society forward, we need all the best minds and information across oceans and borders. Because we can’t afford not to hear the world’s brilliant scientific voices, no matter their immigration status.

That knowledge helped Kwon, at least, submit her first journalistic article for publication. “Now that I know how to do it, I would approach other publications much more easily,” Kwon said. Her advice to other visa-holders interested in writing for the lay press? Be upfront about your visa status with your editor once your piece is accepted. Hopefully, the editor will know how to take it from there.

====== 33 ========

THANKSGIVING AND THE MYTH OF NATIVE AMERICAN "SAVAGES"

Note: This post first appeared on November 21, 2016. It's still relevant, of course.

The approach of Thanksgiving, that quintessential American holiday, has me brooding once again over scientists’ slanderous portrayals of Native Americans as bellicose brutes.

When I was in grade school, my classmates and I wore paper Indian headdresses and Pilgrim hats and reenacted the “first Thanksgiving,” in which supposedly friendly Native Americans joined Pilgrims for a fall feast of turkey, venison, squash and corn. This episode seemed to support the view—often (apparently erroneously) attributed to the 18th-century philosopher Jean-Jacques Rousseau—of Native Americans and other pre-state people as peaceful, “noble savages.”

Prominent scientists now deride depictions of pre-state people as peaceful. “Contra leftist anthropologists who celebrate the noble savage,” psychologist Steven Pinker wrote in 2007, “quantitative body counts—such as the proportion of prehistoric skeletons with ax marks and embedded arrowheads or the proportion of men in a contemporary foraging tribe who die at the hands of other men—suggest that pre-state societies were far more violent than our own.” According to Pinker, the 17th-century philosopher Thomas Hobbes “got it right” when he called pre-state life a “war of all against all.”

Pinker expanded on this claim in his 2011 book The Better Angels of Our Nature. The Hobbesian thesis has been advanced in other influential books, notably War Before Civilization: The Myth of the Peaceful Savage, by anthropologist Lawrence Keeley; Constant Battles: The Myth of the Peaceful, Noble Savage, by archaeologist Steven LeBlanc; War in Human Civilization, by political scientist Azar Gat; The Social Conquest of Earth, by biologist Edward Wilson; and The World Until Yesterday, by geographer Jared Diamond.

Referring specifically to the pre-Colombian New World, Keeley asserted, “The dogs of war were seldom on a leash.” Popular culture has amplified these scientific claims. In the 2007 HBO docudrama Bury My Heart at Wounded Knee, Chief Sitting Bull complains to a U.S. Army colonel about whites’ violent treatment of the Indians. The colonel retorts, “You were killing each other for hundreds of moons before the first white stepped foot on this continent.”

Yes, Native Americans waged war before Europeans showed up. The evidence is especially strong in the American Southwest, where archaeologists have found numerous skeletons with projectile points embedded in them and other marks of violence; war seems to have surged during periods of drought. But as I have asserted in my book The End of War and on this site, Pinker and other Hobbesians have exaggerated warfare among early humans. These scientists have replaced the myth of the noble savage with the myth of the savage savage.

In two momentous early encounters, Native Americans greeted Europeans with kindness. Here is how Christopher Columbus described the Arawak, tribal people living in the Bahamas when he landed there in 1492: “They…brought us parrots and balls of cotton and spears and many other things, which they exchanged for the glass beads and hawks’ bells. They willingly traded everything they owned…. They do not bear arms, and do not know them, for I showed them a sword, they took it by the edge and cut themselves out of ignorance…. With 50 men we could subjugate them all and make them do whatever we want.”

How that passage—which I found in historian Howard Zinn's 1980 classic A People’s History of the United States—captures the whole sordid history of colonialism! Columbus was as good as his word. Within decades the Spaniards had slaughtered almost all the Arawaks and other natives of the New Indies and enslaved the few survivors. “The cruel policy initiated by Columbus and pursued by his successors resulted in complete genocide,” wrote the historian Samuel Morison (who admired Columbus).

A similar pattern unfolded in New England in the early 17th century. After the Pilgrims arrived in Plymouth in 1620 on the Mayflower, they almost starved to death. Members of a local tribe, the Wampanoag, helped the newcomers, showing them how to plant corn and other local foods. In the fall of 1621 the Pilgrims celebrated their first successful harvest with a three-day feast with the Wampanoag. The event my classmates and I reenacted in grade school really happened!

The friendliness of the Wampanoag was extraordinary, because they had recently been ravaged by diseases caught from previous European explorers. Europeans had also killed, kidnapped and enslaved Native Americans in the region. The Plymouth settlers, during their desperate first year, had even stolen grain and other goods from the Wampanoag, according to Wikipedia’s entry on Plymouth Colony.

The good vibes of that 1621 feast soon dissipated. As more English settlers arrived in New England, they seized more and more land from the Wampanoag and other tribes, who eventually resisted with violence—in vain. We all know how this story ended. “The Indian population of 10 million that lived north of Mexico when Columbus came would ultimately be reduced to less than a million,” Zinn wrote.

In “Indians, Slaves, and Mass Murder: The Hidden History,” a recent essay in The New York Review of Books, anthropologist Peter Nabokov notes that colonizers reduced California’s native population from 350,000 at first contact to under 17,000 by 1900. State laws allowed and even encouraged the slaughter of Native Americans. “Extermination,” Nabokov comments, was “considered no great tragedy for an entire people who were uniformly and irredeemably defined as savage and inhuman.”

Centuries earlier, the Arawak and Wampanoag were kind to us—and by us I mean white people of European descent. We showed our thanks by sickening, subjugating and slaughtering them and other indigenous people. And we have the gall to call them more savage than us.

Please ponder this dark irony as you celebrate Thanksgiving.

Addendum: U.S. government maltreatment of Native Americans continues. A United Nations human-rights official accuses “law enforcement officials, private security firms and the North Dakota National Guard” of using “excessive force” against Native Americans and others protesting an oil pipeline that “runs through land sacred to indigenous people.”

Further Reading:

Was Civilization the Cure for Primordial Human Violence?

10,000-Year-Old Massacre Does Not Bolster Claim That War Is Innate.

Quitting the hominid fight club: The evidence is flimsy for innate chimpanzee–let alone human–warfare.

New Study of Foragers Undermines Claim That War Has Deep Evolutionary Roots.

New Study of Prehistoric Skeletons Undermines Claim that War Has Deep Evolutionary Roots.

Survey of Earliest Human Settlements Undermines Claim That War Has Deep Evolutionary Roots.

Chimp Violence Fails to Support Deep-Roots Theory of War.

Margaret Mead’s War Theory Kicks Butt of Neo-Darwinian and Malthusian Models.

RIP Military Historian John Keegan, Who Saw War As Product of Culture Rather than Biology.

War Scholar Critiques New Study of Roots of Violence

War Is Our Most Urgent Problem; Let's Solve It.

*Self-plagiarism alert: This is an updated version of a column posted on previous Thanksgivings.

====== 34 ========

HOW TO VACCINATE A WILD BAT

This probably won’t come as a surprise, but vaccinating wild bats is a difficult task. It’s also an important one: many bat populations are now endangered by white-nose syndrome, a serious fungal disease that invades the skin of bats. The infection causes them to rouse frequently during hibernation, over-expending their energy reserves when they should be in torpor.

There’s a vaccine against the fungus, but this requires painstaking capture and manual application of the medicine. It would be far better to administer vaccine to many bats at once, if it were possible to spray the vaccine onto the bats as they enter and exit their dwellings. The vaccine would then be consumed by the animals as they groom the sprayed material from their fur. Which is why the National Wildlife Health Center, a unit of the U.S. Geological Survey, recently partnered with PARC, a Xerox company, to undertake a wildlife protection project in Madison, Wisconsin. The goal is to explore the use of new spraying technologies to treat wild bats with topical vaccines.

It’s important, not just for the bats themselves; the flying mammals are also a valuable “natural pesticide,” saving farmers in the United States up to $3 billion per year in avoided pest control measures. And bats are better for the environment than pesticides!

Unfortunately, vaccines—and a wide variety of other fluids of medical and industrial interest—are notoriously hard to spray, because the delivery media stiffen as they stretch. This behavior, known as strain hardening, leads to the formation of stable filaments that resist breaking up into droplets, which makes it impossible to create uniform spray. In other words, the more you pull on them, the harder they resist breaking apart. You may have come across this behavior in a commonly encountered strain-hardening fluid: melted mozzarella.

So how to vaccinate large numbers of wild bats without capturing and inoculating them by hand? This is where PARC’s filament extension atomization (FEA) technology comes in. FEA is able to break up the fluid filaments into droplets, taking advantage of strain-hardening behavior to create a uniform mist.

Here’s how FEA works: Two high-speed rollers come together in a contact area known as a nip. As the fluid is pushed through the nip, multiple filaments are formed, stretching and thinning as they are pulled apart by the roller surfaces, before eventually breaking into fine droplets. Of course, a lot of complex engineering goes into making this actually work, but the result is a fine mist that can be captured and directed to where it’s needed. In this case an aerosol, either inhaled or absorbed through the skin, is the most scalable way to vaccinate the largest number of bats with one deployment.

The USGS-PARC team will be led by Tonie Rocke, an expert in wildlife infectious diseases and vaccinations. She explains that up to 90 percent of bat populations in Wisconsin have been depleted by white-nose syndrome in recent years, posing a serious threat to the survival of bats all over North America. The team will first deliver mock vaccines to through aerosol spraying in caves and small mines over the course of two years to maximize uptake by bats, and later, when optimized, the real vaccine will be delivered. PARC will build the prototype spray devices and help with installation and field testing; the USGS team will lead field testing to quantify the physiological responses and effects on the bats.

PARC’s atomizer breakthrough enables a broad range of new spraying applications across a variety of industries. For instance, FEA technology could be used to apply paint in a thin, controllable layer, without the need for harmful VOCs. PARC is currently working with a paint company to investigate using FEA to apply specialized coatings to aircraft. The FEA approach has also been applied to generate polymer powders for additive manufacturing and other industrial uses. There are a wide variety of consumer uses for the technology as well. For example it could be used to spray sunscreen without resorting to foul-smelling formulations that sting users’ eyes.

The flexibility and broad applicability of FEA allow us to reimagine what novel spraying techniques can accomplish today and what may be possible in the near future for a wide variety of industrial and consumer uses. For now, we are hopeful that the USGS-PARC wild bat vaccination project will have a lasting effect to cure bats of white-nose syndrome across Wisconsin and beyond.

====== 35 ========

SAWBACK TURTLE GETS A NEW LOOK

When I think of sea turtles, I think of smooth shells. This is probably because the green sea turtle - with its lovely, sleek carapace - has long been the ambassador for these marine reptiles. But, as a fossil sea turtle from the Cretaceous of Alabama reminds us, different scaly swimmers have long displayed a variety of flashy shell shapes. Take Prionochelys matutina, for example - the “sawtooth turtle.”

You may have seen Prionochelys before in a museum exhibit. This turtle has been known to paleontologists since 1953 and has always stood out from its relatives thanks to the tooth-like protrusions along the margins and center of its shell. The effect is fit for a Teenage Mutant Ninja Turtles villain. But, as Andrew Gentry points out in a new study, the actual osteological architecture of this turtle’s shell is relatively unknown. Incomplete specimens and a lack of referred material have left us with an anatomical gap.

The reconstructed skeleton of Prionochelys seen from below. Credit: Gentry 2018

New specimens from the Cretaceous rock of Alabama, representative of a time when a shallow sea straddled the middle of North America, help fill in our understanding of Prionochelys. Multiple specimens of adults and juveniles present the old sawtooth in new detail. The pointed parts of shell around the edges give Prionochelys a more jagged look - more hawksbill than green - and the center ridge displays rounded points that add to the sawtooth impression. The overall effect is a little more subtle than the almost aggressively-ornamented versions that have been reconstructed before.

On top of that, Gentry writes, the new fossils have helped refine how the several known Prionochelys species relate to other seagoing shellbacks. It appears that Prionochelys groups together with several other fossil sea turtles with bumpy backs on the evolutionary stem that connects to the cheloniids, or the group which includes today’s green, loggerhead, and hawksbill sea turtles, among others. This is despite the fact that some of the shell ornamentation anatomy on Prionochelys resembles that of the leatherback sea turtle, which suggests these features evolved twice independently. Prionochelys just took the construction to a sharper extreme.

====== 36 ========

WHAT HAPPENS WHEN PEOPLE ARE INTENTIONALLY MORE OPEN TO NEW EXPERIENCES?

Since a large part of my research program is investigating the importance of openness to experience, I get asked all the time: Can openness be improved? I always hedge at this question, simply because there is such a dearth of research addressing this topic.

I mean, we know the correlations. And there are a lot of those. Openness to experience-- which can be defined as the drive for cognitive exploration of inner experience-- is positively associated with lots of awesome stuff, including:

So clearly openness is associated with lots of important outcomes in life. But this just means that people who are naturally and spontaneously more open in their daily lives tend to have higher levels of these outcomes in life. Surprisingly, we know very little about whether we can actually do anything to increase trait levels of openness, and what the outcomes would look like if more people intentionally engaged in openness in their daily lives.

As an important first step toward answering these understudied questions, Zachary van Allen and John Zelenski looked at the short-term effects of greater openness engagement. While it may be difficult to fundamentally alter an entire person's personality structure in 5 days, they were curious whether engaging in greater openness in the short-term can at the very least improve important outcomes we know are associated with the trait openness.

The researchers randomly assigned 210 undergrads enrolled in introductory psychology to participant in either the "openness" experimental condition or the "control" condition. All participants completed a battery of tests before the intervention, and then engaged in activities for five straight days.

In the control condition, participants were asked to "record, in as much detail as possible, the happenings of your life in the past 24 hours." Control participants also engaged in a trivia task thought to elicit little or no curiosity. In contrast, activities in the open condition consisted of a series of 15 minute writing assignments that encouraged introspection and cognitive exploration of aesthetics, ideas, and feelings, as well as a trivia task in which the questions were designed to elicit curiosity.*

On the days that participants engaged in the activities, they completed a battery of questionnaires that assessed emotions, creative thinking, authenticity, and effort experienced while completing the tasks. After the five days, all participants took a post-test assessment which included measures of emotions, personal growth, authenticity for the week, and creative thinking. What did they find?

The Effects of Open Engagement

First, creativity. We know that openness to experience is the strongest correlate of creativity. But does instructing people to engage in openness-related activities for 5 days increase their creative thinking, even in the short-term?

It doesn't look like it. While those who were already more open before the experiment generated more alternate uses for an everyday object (a traditional measure of creative thinking), there was no difference between the control condition and the open condition in regards to creative thinking scores. In fact, those in the control condition were more elaborate in their creative responses.

Interestingly, however, those who wrote more words than average in their daily logs (regardless of condition) did show higher creative thinking scores (particularly increased flexibility in their creative thinking). This may speak to the power of expressive writing on creativity-- not to mention the effect of expressive writing on mental health and well-being-- irregardless of the specific content.

In terms of authenticity and personal growth, while preexisting openness levels were associated with authenticity and personal growth, there was zero difference in increasing levels of authenticity and personal growth between the two conditions. However, there was some important nuance. For both authenticity and personal growth, there was an effect of engaging in the openness-related activities for those already scoring high in openness. Also, regardless of condition, those who wrote more during the daily writing tasks reported increasing higher scores on the personal growth scale, again possibly speaking to the power of expressive writing more generally.

Also notably, all participants reported feeling more positive emotions immediately following the open condition activities relative to the control condition activities, but those already scoring high in openness showed particularly higher positive emotions engaging in the openness condition, and those already scoring high in openness showed lower positive emotions in the control condition.

What Does All This Mean?

There is increasing evidence that forcing people to act contrary to their natural dispositions can be detrimental. For instance, while we know that overall (averaging across everyone) extraversion is strongly positively correlated with well-being and happiness, asking introverts to repeatedly engaged in extraverted behavior can lead to increased anxiety and tiredness and decreased feelings of authenticity over time.

Likewise, the results of the current study suggest that the same effects also apply within the domain of openness. Asking people to engage in openness-related activities over the course of multiple days had the strongest effect on those who were already high in openness. Those who already score low in openness probably looked at the activities as a nuisance, whereas those scoring higher in openness were probably energized by the activities.

Whereas I often tout the benefits of openness on creative thinking, intellectual curiosity, imagination, and profoundly emotional and aesthetic experiences, all of this research is an important reminder to me that not everyone cares equally about these outcomes. While I personally think that the laundry list of the correlates of openness I presented at the beginning of this article are important outcomes to cultivate in society (especially in today's society), it appears that asking people to act out of character repeatedly is not the best way to change their behaviors unless they want to change.

I think this is a really important caveat, and I encourage researchers who conduct further research on this topic to measure the extent to which people scoring low on certain personality traits have the motivation to improve those levels. Brent Roberts and his colleagues have found that most people do want to be more open to new experiences, but that's certainly not everyone. I would be interested to see whether the openness-related activities have an effect particularly on those low open people who do wish to change their personality. I'd also be interested in looking at the effects over a longer stretch of time than just five days!

We do know that personality change is possible, but you have to want to change, and be willing to put in the hard work to repeatedly change your behaviors and habits. The good news, however, is that the latest science of personality suggests that with enough adjustments your patterns over time, you can fundamentally change who you are.

--

* For instance, in the " feelings" daily log, participants wrote about their deepest thoughts and emotions regarding two meaningful life events, and in the " introspection" daily log, participants were instructed to rank order 11 values/characteristics in order of personal relevance and explain why they made those choices and when those values/characteristics were particularly important for them. For a complete description of all of their activities, I recommend reading their paper.

====== 37 ========

GROWN-UP STEM PROGRAMS FOR THE YOUNG AT HEART

With gifting season coming up again, it may be time to dig out past ideas for STEM gifts that don’t come in boxes or require batteries. But what about the budding scientists in your life who aren’t quite so young? For an informal evening of problem solving, consider a trip to an escape room. For something a little more hands on, think about a cooking class or time at a local maker space. And don’t underestimate your local library, which can have courses on building websites, learning python, using a 3-D printer, or even circuits 101. Whether they are interested in astronomy or archeology, a mix-and-mingle or an in-depth class, there are programs out there designed for adult learners in your life. Here is a quick glimpse into just a few examples.

Think & Drink with the Extinct: Cleveland Museum of Natural History (Cleveland, Ohio) For anyone who might want to mix and mingle with curious adults, taste the wares of local breweries, and get an up-close view of the museum's dinosaur fossils. You can raise a glass to one of your oldest ancestors with Lucy, and look way back into local history with the Dunkleosteus. It provides a chance for adults to learn informally and explore the museum without the daytime chaos.

Senior Science Days: Dudley Observatory & the Museum of Innovation and Science (Schenectady, New York) The Dudley Observatory and miSci know that a love of science and learning lasts a lifetime. That is why they have designed programming specifically for senior citizens. Older learners can follow up a quiet afternoon at the museum with exciting astronomy lessons targeted just for them. They can learn about Jupiter, get an update on the Curiosity Rover, learn about getting humans to Mars, or even spend an evening learning about the origins of the universe.

Community Archaeology Program for Adults: Binghamton University (Binghamton, New York) For those whose interests run more Indiana Jones than Jurassic Park, this program creates a chance for members of the public (ages 16 and up) to join a real archeological field project. Participants get to work alongside professional archeologists to help excavate at a nationally important site. They will build their own basic archeological skills and learn about the prehistory of New York State.

Adult Courses at the American Museum for Natural History (New York, New York) For those who miss the classroom, the AMNH offers courses designed for adult learning. They can learn how artists and scientists work together to rebuild the faces of our extinct human relatives – and build their own. They can learn about the science behind sleep and memory, explore the ways our brains translate information from our senses to perceptions in our brains, or even learn how to navigate through the Digital Universe to lead their own tour like the pros at Hayden Planetarium.

Twiga Adult Overnights: Cincinnati Zoo (Cincinnati, Ohio) Hors d-oeuvres and drinks and zoo animals – oh my! Go behind the scenes to learn about the animals and what it takes to care for them. Then enjoy a bonfire and spend the night in a tent. To finish up, share breakfast with your fellow adventurers and have a special close encounter with the giraffes. For 21+.

====== 38 ========

BUILDING A NEW GENERATION OF SCIENCE POLICY ADVOCATES

In an era of “alternative facts” and polarized politics that spurns scientific consensus, it is more important than ever that scientists are not only allowed but encouraged to be engaged in public and political discourse.

With the scientific community still battling the isolationist, siloed philosophy that has traditionally defined our interactions with the public, we are fortunate that many young scientists are rising to this occasion of public need. Despite the antisocial stereotypes associated with scientists and engineers, many enthusiastically pursue opportunities to translate our science via public outreach and communication.

One important facet of this outreach is applying their skills to governance and policy, which is where the National Science Policy Network (NSPN) comes in. Our mission is to provide resources, networking and training to the growing groups of scientists and engineers who want to serve as both advocates and advisors in the public sector.

It is essential that our generation of scientists and engineers strives to remove barriers to amplifying our collective voice and that we build solidarity among those who want to engage with their community as informed citizens. Social networks like Twitter and Facebook have allowed many of us to engage and support each other online, but building and strengthening our community requires moving from behind the computer screens to humanize and connect young scientists to each other and to the general public.

This past weekend NSPN hosted its annual symposium. The event was a critical step towards challenging a rusted status quo of distant scientists and showcasing the strength and numbers of our community. The symposium brought together over 250 young science professionals for a weekend of building connections and catalyzing action. We hosted a variety of speakers and panels ranging from Science Advocacy 101 to a panel on rebuilding a sustainable and resilient Puerto Rico through science.

To bridge the widening gap between scientific expertise and public policy change, NSPN has created several ongoing initiatives that aim to build capacity and empower early career scientists who cannot find support within their academic institutions. Our first round of microgrants were recently awarded to seven groups nationwide, supporting projects in media, outreach and training. At the symposium, we announced an international policy memo competition and launched another round of microgrants. Moving forward, our goals include the creation of an open-access science policy curriculum and internship opportunities for members of our network.

We are building a community of scientists who recognize the potential of their hard-earned skills in technical thinking and deductive reasoning. This symposium showcases the growing momentum of these future leaders and empowers our members to elevate science policy as a legitimate and valuable career path. We believe that this is a critical step towards a future of evidence-based policymaking and public dialogue. Are you with us?

====== 39 ========

WORLD'S LARGEST ORGANISM FACES BLEAK FUTURE

It lives in south-central Utah. And it’s huge. In fact, it is thought to be the largest living thing on the planet. It’s a stand of trees, a field of aspens all clones and all connected at the roots. Called Pando, the grove was first characterized by scientists in the 1970s, and it’s probably existed for many thousands of years. But now a study finds that this this massive, ancient organism is failing.

“More than 80 percent of the entire Pando clone is in a nonsustainable state that has the potential to collapse and significantly reduce the size of this world’s largest organism in the next 10 to 20 years.” Paul Rogers, director of the Western Aspen Alliance at Utah State University.

The cause of this crisis? Herbivores, mostly deer. Parts of Pando are fenced off, but that section is still under attack. “Young aspen trees are so nutritious that animals really want to get them, particularly late in the year when the rest of the forest plants are senest and dried up..., I think that there’s perhaps some very healthy [animals that] are able to jump over the eight-foot fence.”

The deers’ aggressive browsing of young aspen poses a huge threat to Pando. “We see a big gap in the demography. And I often use the human analogy that this is a forest that is almost completely composed of senior citizens, and we have no mature, healthy individuals, we have no middle-aged, we have no teenagers, we have no babies. And that’s a really dangerous situation for aspen because it really depends on continuous growth of the whole clone. You should have a really diverse age and height structure.”

The problem has largely been created by humans and our game management strategies. Rogers says those strategies need to be reconsidered if we want to protect Pando. And it’s not just about saving the world’s largest organism for its own sake.

“Aspen here and, in fact, worldwide harbor great amounts of biodiversity…, hundreds of plants and animals that are dependent on aspen ecosystems. In the Western U.S., the lower 48, aspen, second to riparian systems, are the most biodiverse forests that we have. Another term for that is Aspen is a keystone species. So as aspen goes so do all those dependent species. So that’s the number one reason.

“Specific to Pando, this closely demarcated 106 acres or 43 hectares is something that’s workable that we can see and feel and look at and people know about or are learning more about. And so…as a conservation symbol it’s like, if we can’t fix this one thing that has this international reputation, what does that say about our greater relationships with the Earth and living compatibly with the planet?”

—Annie Sneed

[The above text is a transcript of this podcast.]

====== 40 ========

U.S. IMMIGRANTS LEAVE COUNTRY&MDASH;AND MICROBES&MDASH;BEHIND

Immigrants to the U.S. might lose touch with certain customs and traditions back home. But here's something else they lose: their microbes.

"When they came to the U.S. almost immediately they began losing their native microbes." Dan Knights, a computational biologist at the University of Minnesota. "And over time the balance shifted to the point where they were dominated by the U.S. associated microbes."

He's referring to first- and second-generation immigrant women, from the Hmong and Karen ethnic minorities in southeast Asia. His team sequenced the DNA found in their feces.

And they saw that there was an immediate decline in the number and diversity of gut microbes among the immigrants, compared to their counterparts still living back home. And the decline continued over time.

If you're thinking, well, maybe the women just switched up their diets - started eating more hamburgers, more bacon and eggs? Dietary surveys don't bear that out. The women weren't changing their diets nearly fast enough to explain the drop in diversity.

"It seems as though there's something else going on that has to do with the U.S. lifestyle… Antibiotics could be playing a role. The water supply could be playing a role. Could be other aspects of lifestyle, stress, exercise, hygiene. But we don't have enough information yet to be able to pin it down."

The results are in the journal Cell. [Pajau Vangay et al., US Immigration Westernizes the Human Gut Microbiome]

Some of the missing microbes helped digest traditional foods like tamarind, palm and coconut. But the consequences could be more severe than indigestion. "We have evidence from many studies now, especially even causal evidence in a number of animal studies, that having the wrong set of microbes, or missing the right set of microbes, can cause many of the diseases that are rising in industrialized nations." Things like obesity, metabolic disease.

Which we might be able to fix, he says, if we're able to solve this microbial mystery.

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 41 ========

SCIENCE NEWS BRIEFS FROM ALL OVER

Hi, I’m Scientific American podcast editor Steve Mirsky. And here’s a short piece from the November 2018 issue of the magazine, in the section called Advances: Dispatches from the Frontiers of Science, Technology and Medicine.

The article is called Quick Hits, and it’s a rundown of some science and technology stories from around the globe, compiled by editorial contributor Ankur Paliwal.

====== 42 ========

BABIES AND CHIMPS SHARE A LAUGH

A baby's laugh is unmistakable: <CLIP: baby laughter> But aside from its squealing, high-pitched quality, there's another factor that sets a baby's laugh apart from ours: babies laugh on the exhale and on the inhale. Whereas adult humans "tend to laugh predominantly on the exhale. The classic kind of 'ha ha ha.'" Disa Sauter, a psychologist who studies emotions at the University of Amsterdam.

Sauter and her colleagues collected 44 samples of babies laughing, from the ages of 3 months… <CLIP: 3 months> to 10 months…<CLIP: 10 months> all the way up to 18 months <CLIP: 18 months>.

They played the samples for about 100 untrained volunteers, and asked them to deconstruct the laughs. Were the babies laughing on the inhale, the exhale, or both? "And there we find a nice relationship between the age of the baby and the amount of the laughter happening on the inhale."

The younger the baby, the more laughs on the inhale. Because remember, our laughs gravitate towards the exhale as we age. And Sauter thinks one reason for that could be that we gain more vocal control as we learn to talk: speaking also happens primarily on the exhale.

She presented the preliminary findings at a meeting of the Acoustical Society of America, in Victoria, Canada. [Disa Sauter et al., How do babies laugh?] The researchers are in the process of checking the judgments of the volunteers against those of professional phoneticians.

As it happens: human babies aren't the only primates who laugh both breathing our and breathing in. <CLIP: chimp> Chimps do it, too.

"They laugh like 'hoo hoo hoo.' They laugh more continuously while inhaling and exhaling. It's totally difficult to do on purpose."

But Sauter, I thought, pulled off a pretty good impression. "I'll take that as a compliment! <laughs>"

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 43 ========

SINGING FISH REVEAL UNDERWATER BATTLES IN THE AMAZON

Six years ago, the fish ecologist Rodney Rountree was on a skiff in the Peruvian Amazon. He was holding a piranha in his hand…underwater…in a river filled with other piranhas. Maybe, hungry ones.

"That thought crossed my mind a little bit. The water was essentially no visibility. So I did worry a little bit about that but there was no other way to do it."

The job he needed to do? "Audition them, for sound production." Because Rountree studies the sounds fish make. His nickname—and the name of his company: "The Fish Listener."

So his team would catch a fish, reel it in and identify it. And then Rountree would hold it underwater, near a hydrophone, to capture the sounds it made. Like this one, from a red piranha. <CLIP: piranha sound>

"A lot of people call it a bark. I sometimes thought of it as a honk."

The fish make the sound, he says, by pushing and pulling on their swim bladder with the surrounding muscles. Overall, Rountree auditioned 129 piranhas, of four different species. Along with dozens of other river species, like catfish. And he found that he could differentiate individual piranha species by analyzing factors like pitch and harmonics and number of barks.

His colleague Francis Juanes presented the work at the Acoustical Society of America meeting in Victoria, Canada. [Rodney Rountree, Francis Juanes: Sounds from the Amazon: Piranha and Prey]

Rountree also recorded 10 hours of underwater soundscapes, like this one, captured during a piranha feeding frenzy. <CLIP: noisy river> There's a piranha honk, he says, and lots of catfish screeching. Which suggests that, with a bit more study, underwater recordings like these might give us a clearer glimpse of who's doing what, in murky waters.

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 44 ========

SOCIAL CONSTRUCT OF RACE IMPOSES BIOLOGY

“So humans are really really good, or at least Western traditionally educated humans are really, really good at categorizing things into types.”

Jennifer Raff. She’s an anthropologist at the University of Kansas. Raff spoke last month at New York University’s Journalism Institute.

“And if you go back through the history of physical anthropology, which we now call ourselves biological anthropologists to distance ourselves from that history, we as a discipline have a lot to answer for. Because we were the ones who measured crania, measured skulls, to try to come up with…we called it the Caucasoid, and the Negroid and the Mongoloid types, right, this ideal specimen of a cranium that fit these perfect measurements. And that was the type. And we tried to fit in then every other person into one of these categories, and that…really influenced eugenics.

“We still have that notion, are you this group, are you that group, when in reality we’re mixtures, most of us are very mixed. We have lots of ancestry from lots of populations. So if we can stop thinking of these categories as these fixed entities, we’ll get somewhere.”

Raff later noted that race does involve biology—but as an effect.

“But that doesn’t mean that these racial categories aren’t real in some sense. And what I mean by that is, yes, they are culturally constructed categories, but they actually have biological effects…when we create the race ‘black’ or ‘African-American’ or whatever we’re going to call it, we put people into that category regardless of their genetic background, right?

“So, I always come back to this example: President Obama is just as much Irish as he is African-Am-, but we code him as black, right…, when we do that, when we categorize and classify people—that can have biological effects. We know that stress levels in African-Americans are chronically high, because of racism, because of structural racism, these categories that we’ve created, right? That is biological, that’s real. It may not be because of the genetic variants that they had or there may be some complicated interaction there, but these categories that we create, these social categories, have biological effects.”

—Steve Mirsky

[The above text is a transcript of this podcast.]

====== 45 ========

FIRST BENEFIT OF KNOWING YOUR GENOME

“I think if genome sequencing gets just super cheap then it’s…probably very soon going to make sense to just sequence all your DNA.”

Science journalist Carl Zimmer, author of the book She Has Her Mother’s Laugh: The Powers, Perversions and Potential of Heredity. Zimmer spoke last month at New York University’s Journalism Institute. Right now, commercial genome services only look at a small percentage of all your DNA. But as the cost plummets, you’ll get your entire genome.

“Then the issue will become, well, what do you use your genome for in terms of your health. A lot of people will actually benefit from something I learned by looking at my genome, which is, that if God forbid I were to get hepatitis there are certain drugs that won’t do me any good. Because I have certain genes. Pharmacogenomics, as it’s called. I think that pharmacogenomics might be kind of the low-hanging fruit of genome sequencing. Because, doctors so often, if you get sick, they’re like, well, let’s try this. It might be hepatitis, it might be depression, all sorts of things, like, well, that didn’t work very well, let’s try this. Wouldn’t it be nice if we could just skip the stuff that doesn’t work and go to the stuff that does? So that might be kind of where medicine goes in terms of using our genomes and understanding how heredity affects your health.”

—Steve Mirsky

[The above text is a transcript of this podcast.]

====== 46 ========

FOR HALLOWEEN, CONSIDER THE CHOCOLATE MIDGE

As you unwrap a Halloween candy or two, it's worth paying your respects to the real reason for many of the treats: a tiny fly whose trick is to make chocolate possible.

"They're all in the family Ceratopogonidae, which is the biting midges family. But not all of the adults bite. How we usually do it is we call them 'Cerats.'" Erica McAlister is a fly scientist at the Natural History Museum of London, and author of The Secret Life of Flies.

The "cerats"—related to no-see-ums—do a job that's very hard to get done by hand: they crawl through long, twisty cacao flowers, pollinating the stubborn cacao tree. Which produces the beans used to make chocolate.

"They are really, really difficult to pollinate. So you do need these little things to do it."

And to McAlister, at least, the tiny midges are a beautiful sight to behold. "They look like a very tiny mosquito, but they are basically absolutely covered in hair, they're very beautiful, very hirsute little organisms. And the males have got the most—they look like feather duster antennae. He's got to not only smell for the female, he's listening. And his ears are on the antennae. They're not very robust, these things, they're tiny, as the name implies. They've got nice external genitalia for the boys… I don't know what else you want me to say <laughs>"

Well, here's the bad news: The chocolate midges are in danger, as farmers clear out shade-grown rainforest plots, in favor of sunnier monocultures of cacao. That threatens the tiny flies, which need the damp rotting leaf litter of the forest floor to thrive. But some producers are taking notice.

"Obviously our human demand for chocolate has gone up, so now a lot more research is going into fly pollinators, including these as well."

As for McAlister? She won't be joining you on that chocolate binge. "I can't stand it. Revolting stuff."

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 47 ========

DOLPHINS DUMB DOWN CALLS TO COMPETE WITH SHIP NOISE

The oceans are getting louder. And coastal areas are some of the noisiest, as in this underwater recording, captured 17 miles off the coast of Ocean City, Maryland. <Maryland boat noise clip>

The noise could be a problem for marine mammals, which, like us, use sound to communicate. "Just like if we're in a noisy bar, we have to shout to each other, they might have to do that too." Helen Bailey is a marine biologist at the University of Maryland Center for Environmental Science.

She and her colleagues recorded two months of underwater sounds, in that same area off the coast of Maryland. They used automated software to fish out 200 bottlenose dolphin whistles from the noise, and visually compared the spectrograms. Here's a normal whistle. <whistle clip>

But what they found was that dolphins dumbed down the complexity of their whistles and raised their pitch, when they were competing with shipping noise. <whistle clip 2> Which apparently helps, but could also hurt, their ability to communicate.

"By using simpler calls, yes, there is a risk they're not communicating as much information as they would if it was quieter. Also for younger dolphins they actually learn these sounds from hearing other dolphins. So they're hearing this much simpler language."

The results—and a few of those spectrograms—are in the journal Biology Letters. [Leila Fouda et al., Dolphins simplify their vocal calls in response to increased ambient noise]

The survey site is the proposed future home of a wind farm - which could mean lots of noise as the huge towers are installed. Until then, it's the chronic roar of ships and boats that Bailey wants people to ponder. "I think people think about boats in terms of the emissions, just like with cars. And I think what we need to think about is sound is also an emission."

—Christopher Intagliata

[The above text is a transcript of this podcast.]

====== 48 ========

ASOCIAL OCTOPUSES BECOME CUDDLY ON MDMA

When humans take the drug MDMA—best known as ecstasy—they feel a deeper connection to others—emotionally and physically. Because MDMA affects serotonin, a nervous system chemical.

“Serotonin is one of the oldest neurotransmitters.” Gul Dolen, an assistant professor of neuroscience at Johns Hopkins University who studies social behaviors.

“It's been implicated in all kinds of functions, lots of them having nothing to do with social, and so we wanted to know, how long ago was serotonin's function really about encoding social behaviors?” So Dolen and her colleague did what any scientist would do: they gave MDMA to octopuses.

Octopuses are asocial creatures, and their last common ancestor with us lived more than a half billion years ago. Which made them a good test subject for the question at hand.

The researchers set up a simple test: “There’s a large chamber, which is basically an aquarium tank, divided it into three chambers. On one side, we put a little overturned flowerpot that's clear and plastic and has lots of holes in it. Underneath that overturned pot, we have a toy object, and on the other side, we have another overturned orchid pot, but this one has an octopus in it.”

The researchers put an octopus in the middle chamber and watched it swim around for thirty minutes. They measured how much it interacted with on e side of the chamber—the one with the other octopus—versus the chamber with the toy. Then they soaked the test octopus in a beaker of MDMA , put it back in the aquarium and watched it for another thirty minutes. And what the researchers saw was weirdly similar to a human on MDMA:

“Before they received MDMA when they were interacting, they're very reserved, even when they're spending time in the social side, they are sort of mashing their bodies up against the side wall, and extending only one arm out to touch the flowerpot, and very tentatively touching with one arm…. After MDMA, all of the animals spent significantly more time in the side that had the other octopus in it. What's more is that the quality of their social interactions—they were much more loose in their body posturing, they were allowing several arms to touch the sides of the flowerpot, sort of hugging around the flowerpot, and exposing the bottom part of their body to the other octopus which, the way they were doing that, was suggesting they were exploring rather than any kind of aggressive posturing.”

These observations indicate that serotonin began playing a role in animals’ social behavior more than 500 million years ago.

Dolen says these findings could help scientists better understand social behavior, as well as give clues about possible treatments for serotonin-related human conditions like schizophrenia and PTSD.

Meanwhile, we’ve learned—not surprisingly, given their anatomy—that octopuses are excellent huggers.

—Annie Sneed

[The above text is a transcript of this podcast.]

[Eric Edsinger and Gül Dölen, A Conserved Role for Serotonergic Neurotransmission in Mediating Social Behavior in Octopus, in Current Biology]

